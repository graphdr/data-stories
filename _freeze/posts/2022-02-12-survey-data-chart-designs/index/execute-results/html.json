{
  "hash": "eddcf01d3deabbedd8466be242142adb",
  "result": {
    "markdown": "---\ntitle: \"Survey data chart designs\"\ndescription: |\n  Comparing chart designs for displaying Likert-style survey results and concluding that the 100% stacked-bar chart is the most effective.\ndate: \"2022-02-12\"\ndate-format: \"YYYY-MM-DD\"\ndraft: false\ncategories: [R, Data storytelling, Engineering education]\nimage: \"thumbnail.png\"\ncap-location: margin\n---\n\n\n\n\n:::{.callout-note}\n## Summary \n<small><em>I reconstruct three alternative chart designs for Likert-style survey data from a 2018 post by Lisa Charlotte Muth and Gregor Aisch and share the   source data and my R code. Comparing the charts in light of their arguments, I agree that the 100% stacked-bar chart is the more effective of the three designs.</em></small>\n:::\n\nFor a recent presentation, I needed to graph the results of a Likert-style survey.  \n\nIn the past I tended to use the diverging stacked-bar design by Robbins and Heiberger [-@Robbins+Heiberger:2011; -@Heiberger+Robbins+2014]. Browsing for alternatives, I found the essays by Stephen Few [-@Few:2016] and Lisa Charlotte Muth and Gregor Aisch [-@Muth+Aisch:2018] to be well-reasoned and useful. \n\nIn this post, I reconstruct the three chart designs from Muth and Aisch with two goals in mind: to reproduce and comment on the comparisons they make using a data set of my choosing; and to share the source data and my R code. \n\nHere, however, I do not discuss the R code in any detail. In a [companion post](posts/2022-02-13-survey-data-io/index.html), I focus on R for preparing different forms of source data for the likert package and editing the results for publication-ready charts. \n\nI primarily use data.table, ggplot2, and likert R packages. An appealing feature of likert is its compatibility with data.table and ggplot2 functionality. Note that to reproduce this work, likert must be at least version 1.3.6.\n\nThe R code for the post is listed under the “R code” pointers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# packages\nlibrary(\"data.table\")\nlibrary(\"ggplot2\")\nlibrary(\"likert\")\nlibrary(\"cowplot\")\n\n# chart design elements\nneutral_color <- \"gray90\"\nmy_breaks <- seq(-100, 100, 10)\nmy_vline  <- geom_vline(xintercept = my_breaks, color = \"white\", size = 0.25)\nmy_hline  <- geom_hline(yintercept = my_breaks, color = \"white\", size = 0.25)\n\n# ggplot() theme settings\nmy_theme_elements <- theme(panel.background = element_blank(),\n                           legend.key.size = unit(4, \"mm\"),\n                           legend.title = element_blank(),\n                           axis.ticks = element_blank(), \n                           legend.justification = 0.5, \n                           legend.position = \"top\")\n\n# labeling vectors\nopinion_labels <- c(\"Strongly Disagree\", \n                    \"Disagree\", \n                    \"Neutral\", \n                    \"Agree\", \n                    \"Strongly Agree\")\n\nquestion_labels <- c(\"Beyond the content\", \n                     \"Analyze errors\", \n                     \"Provide facts\", \n                     \"Develop writing\", \n                     \"Independent learning\")\n\n# rename opinion columns\nsetnames_opinion_labels <- function(x) {\n  setnames(x, \n           old = c(\"str_disagree\", \"disagree\", \"neutral\", \"agree\", \"str_agree\"), \n           new = opinion_labels, \n           skip_absent = TRUE)\n}\n```\n:::\n\n\n\n\n\n\n\n\n\n## Data\n\nThe practice data in my example are from an engineering education article by Ashanthi Maxworth (2021), selected because the data are compact and the survey includes a Neutral option. The table from the original article is shown below. There were 31 respondents.\n\n![(Original Table 3) Percentage student responses for each question in the feedback form.](survey-data.png)\n\nSurvey data are most likely to be reported in one of three forms: summary percentages (as above), summary counts, or row-records. The `likert()` function accepts any of these forms as input. The practice data, in all three forms, are available in the [blog data directory](https://github.com/graphdr/data-stories/tree/main/data/) in CSV files, though for this post I will use the summary count form only.  \n\nRead the prepared data file in summary count form.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read prepared data\ndt <- fread(\"data/case-study-2021-count.csv\")\n```\n:::\n\n\n<small>\n\n::: {.cell}\n::: {.cell-output-display}\n|q_no | str_disagree| disagree| neutral| agree| str_agree|\n|:----|------------:|--------:|-------:|-----:|---------:|\n|Q1   |            2|        0|       8|    12|         9|\n|Q2   |            2|        2|       7|    14|         6|\n|Q3   |            1|        1|       5|     9|        15|\n|Q4   |            0|        2|      10|    12|         7|\n|Q5   |            2|        0|       6|    11|        12|\n:::\n:::\n\n</small>\n\nI rename the first column `Item`, and the data frame is ready to input to the `likert()` function. Because my goal is comparing chart designs, I'm not  interested in the specific survey questions, so I leave the question labels in their abbreviated form (Q1, Q2, ...). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rename first column\nsetnames(dt, \"q_no\", \"Item\", skip_absent = TRUE)\n\n# examine the result\ndt[]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Item str_disagree disagree neutral agree str_agree\n   <char>        <int>    <int>   <int> <int>     <int>\n1:     Q1            2        0       8    12         9\n2:     Q2            2        2       7    14         6\n3:     Q3            1        1       5     9        15\n4:     Q4            0        2      10    12         7\n5:     Q5            2        0       6    11        12\n```\n:::\n:::\n\n\nThe salient characteristics of the data frame are:\n\n- One row per question\n- First column is named Item and contains the question labels\n- Remaining columns are named for the opinion levels in increasing order left to right\n- Column values are the counts of respondents choosing that option\n- The sum of row counts is the number of respondents answering that question\n\n\n\n\n\n\n\n## Diverging stacked bars\n\nA defining feature of the divergent stacked-bar is that the Neutral segment is split half to the left and half to the right of the zero reference line. Also, because each row of the data table sums to 100%, each bar of the chart has a horizontal length of 100%, partitioned to show the component percentages.  \n\n\n::: {.cell fig.asp='0.35'}\n\n```{.r .cell-code}\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# set scale limits to fill the data rectangle\nmy_limits <- c(-25, 86)\n\n# recode the opinion options\nsetnames_opinion_labels(likert_list$results)\n\n# create the chart\nplot(likert_list, \n     centered = TRUE,              # diverging\n     include.center  = TRUE,       # neutral included\n     plot.percent.low     = FALSE,\n     plot.percent.neutral = FALSE,\n     plot.percent.high    = FALSE) +\n  \n  # additional ggplot components\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     labels = abs(my_breaks)) +\n  my_theme_elements +\n  my_hline\n```\n\n::: {.cell-output-display}\n![Diverging stacked-bar design](index_files/figure-html/fig-div-stacked-bar-1.png){#fig-div-stacked-bar width=672}\n:::\n:::\n\n\nThe top-down row order is by decreasing agreement totals (Agree + Strongly Agree). In contrast, by Heiberger and Robbins' definition, the row position of Q2 and Q4 would be swapped so that the maximum endpoint monotonically decreases top to bottom. \n\nDescribing a diverging stacked bar chart, Robbins and Heiberger say, \n\n> It is difficult to compare lengths without a common baseline. In this situation, we are primarily interested in the total percent to the right or left of the zero line; the breakdown into strongly or not is of lesser interest so that the primary comparisons do have a common baseline of zero [@Robbins+Heiberger:2011, 1060]. \n\nI agree---if we assume the Neutrals can treated as half positive and half negative. Muth and Aisch point out that we have no way of knowing that this is true. Because being truthful is a first principle of ethical data visualization, this assumption makes me uneasy. A lot depends on how the survey questions are worded and how the people surveyed interpret the Neutral response. In this specific case, I'm not certain the Neutrals can  treated as half positive and half negative. Thus, the zero reference line does not establish a common baseline and we lose the ability to make effective visual comparisons. \n\nWe can recover the common baseline at zero by moving Neutral to a side chart of its own. \n\n \n \n \n \n\n \n\n\n\n\n\n## Neutral on the side\n\nBy removing the Neutral responses, the zero reference line is a common baseline\nfor visually comparing total agreement. We can see that the top-down row order is by decreasing agreement totals (Agree + Strongly Agree). And for a given row,  we can visually compare total disagreement to total agreement. \n\n\n::: {.cell fig.asp='0.35'}\n\n```{.r .cell-code}\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# set scale limits to fill the data rectangle\nmy_limits <- c(-13, 78)\n\n# recode the opinion options\nsetnames_opinion_labels(likert_list$results)\n\n# extract Neutrals for second chart\nlikert_list_neutral <- likert_list$results[, .(Item, Neutral)]\n\n# delete Neutrals from likert list (removing neutral from legend)\nlikert_list$results[, Neutral := NULL]\nlikert_list$levels  <- likert_list$levels[!likert_list$levels %in% \"neutral\"]\nlikert_list$nlevels <- likert_list$nlevels - 1\n\n# create the chart\nplot1 <- plot(likert_list, \n              centered = TRUE,               # diverging\n              plot.percent.low     = FALSE,\n              plot.percent.neutral = FALSE,\n              plot.percent.high    = FALSE) +\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     labels = abs(my_breaks), \n                     expand = c(0, 0)) +\n  my_theme_elements +\n  my_hline\n\n# display\nplot1\n```\n\n::: {.cell-output-display}\n![Diverging stacked bar, neutral omitted.](index_files/figure-html/fig-omit-neutral-1.png){#fig-omit-neutral width=672}\n:::\n:::\n\n\nNext I construct the second part of the chart (using ggplot2 functions only) to plot the Neutral responses alone. \n\n\n::: {.cell fig.asp='0.35'}\n\n```{.r .cell-code}\n# use Neutral data frame from earlier\nlikert_list <- likert_list_neutral\n\n# set scale limits to fill the data rectangle\nmy_limits <- c(0, 33)\n\n# extract order of questions (factors) from previous chart object\nfactor_levels <- levels(plot1$data$Item)\n\n# factors for ordering rows \nlikert_list[, Item := factor(Item, levels = factor_levels)]\n\n# assign a variable to fill by and create a legend\nlikert_list[, opinion := \"Neutral\"]\n\n# create the chart\nplot2 <- ggplot(data = likert_list, mapping = aes(x = Neutral, y = Item, fill = opinion)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"\", y = \"\") +\n  scale_x_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     expand = c(0, 0)) +\n  scale_fill_manual(values = neutral_color) +\n  my_theme_elements +\n  my_vline\n  \n# display\nplot2\n```\n\n::: {.cell-output-display}\n![Neutral responses only.](index_files/figure-html/fig-neutral-only-1.png){#fig-neutral-only width=672}\n:::\n:::\n\n\nI combine the two charts and adjust their proportions to make equal scale divisions the same length. \n\n\n::: {.cell fig.asp='0.35'}\n\n```{.r .cell-code}\n# edit Neutral bar chart aesthetics before combining \nplot2 <- plot2 +\n  theme(axis.text.y = element_blank(), \n        legend.justification = -0.25)\n\n# set plot proportions by trial and error until scales match\nwidth_1 <- 0.71\nwidth_2 <- 1 - width_1\n\n# combine plots \nggdraw() +\n  draw_plot(plot1, x = 0      , y = 0, width = width_1, height = 1) +\n  draw_plot(plot2, x = width_1, y = 0, width = width_2, height = 1)\n```\n\n::: {.cell-output-display}\n![Diverging stacked bar chart with neutral on the side.](index_files/figure-html/fig-div-bar-sep-neutral-1.png){#fig-div-bar-sep-neutral width=672}\n:::\n:::\n\n\n> Designed in this way, differences between positive and negative results now stand out a bit more, the sum of Agree and Strongly Agree are easier to read, and the Neutral values are both easier to read and compare [@Few:2016]. \n\nAs Muth and Aisch point out, this design gives a good idea of the \"competition\" between agreement and disagreement. In this case, across all questions more than 60% of the respondents agreed and in all but one instance fewer than 10% disagreed. \n\nIn addition, between 15-30% responded Neutral. We don't know if that means \"I don't know\"  or \"I have no opinion\" or \"Sometimes I agree and sometimes I don't\"or  \"I'm tired of answering Likert-style surveys\" or something else---which is a very good reason to graph Neutral on the side. \n\nI like this design. \n\n\n\n\n\n\n\n## 100% stacked bars \n\nThe final of the three designs is the 100% stacked bar---which until now I have not considered as effective as diverging stacked-bars at conveying survey results. What makes the difference today is Muth and Aisch's suggestion to add a secondary scale along the top of the chart---a simple and elegant contribution. \n\n\n::: {.cell fig.asp='0.35'}\n\n```{.r .cell-code}\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# set scale limits\nmy_limits <- c(0, 100)\n\n# recode the opinion options\nsetnames_opinion_labels(likert_list$results)\n\n# create the chart\nplot(likert_list, \n     centered = FALSE,              # 100% stacked bars\n     include.center  = TRUE,        # include neutral\n     plot.percent.low     = FALSE,\n     plot.percent.neutral = FALSE,\n     plot.percent.high    = FALSE) +\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     sec.axis = sec_axis( # second scale\n                       trans = function(z) z - 100, \n                       breaks = my_breaks, \n                       labels = as.character(abs(my_breaks)))) +\n  my_theme_elements +\n  my_hline\n```\n\n::: {.cell-output-display}\n![100% stacked bar chart.](index_files/figure-html/fig-00-pct-stacked-bar-1.png){#fig-00-pct-stacked-bar width=672}\n:::\n:::\n\n\nWith the right boundary as a baseline, I read the top scale for agreement percentages; with the left boundary as a baseline, I read the bottom scale for disagreement percentages. We can easily quantify a comparison between strong opinions (outer left and outer right) or between total agreement and total disagreement. Neither of the divergent stacked-bar charts allow this level of direct visual access (though the bar segments could be directly labeled with their respective percentages). \n\nLike the previous chart, the rationale for ordering the rows is clear---the agreement total monotonically increase from bottom to top. Of lesser importance, this design also immediately communicates that the bar segments are parts of a whole---that each bar represents 100% of responses. \n\nThe only disadvantage of this chart compared to the previous one is that the relative proportions of the Neutral responses are harder to compare. Neutrals are important data but the main story is usually a comparison between people who have opinions---that is, the bar segments to the left and right of the Neutral center. \n\nI have to agree with Muth and Aisch---this is an effective design.  \n\n\n\n\n\n\n\n\n\n## Back to the story\n\nWere I to prepare this chart to accompany the original article, I might label the rows with shortened forms of the questions and cite the full questions in the text or in the data table. (Alternatively, `likert()` does have an argument to help manage longer question text.)\n\n\n::: {.cell fig.asp='0.35'}\n\n```{.r .cell-code}\ndt_story <- copy(dt)\n\n# recode the opinion options\nsetnames_opinion_labels(dt_story)\n\n# recode the question labels\ndt_story[, Item := question_labels]\n\n# create the likert list\nlikert_list <- likert(summary = dt_story)\n\n# set scale limits\nmy_limits  <- c(0, 100)\n\n# create the chart\nplot(likert_list, \n     centered = FALSE, \n     include.center  = TRUE, \n     plot.percent.low     = FALSE,\n     plot.percent.neutral = FALSE,\n     plot.percent.high    = FALSE) +\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     sec.axis = sec_axis( # second scale\n                       trans = function(z) z - 100, \n                       breaks = my_breaks, \n                       labels = as.character(abs(my_breaks)))) +\n  my_theme_elements +\n  my_hline\n```\n\n::: {.cell-output-display}\n![Editing the legend key and question labels for readability.](index_files/figure-html/fig-editing-labels-1.png){#fig-editing-labels width=672}\n:::\n:::\n\n\nAs an example of the results discussion in the article, the \"provide facts\" paragraph states,\n\n> In the third feedback question, 24 out of 31 students (77.4%) agreed that the case study motivated them to provide facts such as calculations and simulations to support their answers. Unlike a typical textbook problem where there is a definite answer, making an argument in a case study requires thinking beyond the material delivered in class. Therefore, the use of additional calculations and especially simulations were needed to support the argument [@Maxworth:2021].\n\nThis is a perfectly straightforward description of the result and the chart supports the argument visually. In terms of the larger narrative, however, the chart provides a rationale for revising the narrative framework---instead of discussing the results in question order (Q1, Q2, ...), discuss the results in order of level of agreement (highest to lowest), supported visually by the row order in the chart (top to bottom). \n\nI think the chart provides evidence for an additional assertion: that the preponderance of responses are *positive*, \n\n- Between 61-77% of responses were positive over the full range of survey statements. \n- The largest negative response was to the Analyze errors/misconceptions assertion at 13% (4 out of 31 responses); all other negatives were at 6.5% (2 of 31). \n\nGiven the overall positive response, the small number of negatives may have resulted from a mismatch between a student and the case they selected. As the author states in their conclusion, \n\n> In future implementations, an effort is needed to balance the choice distribution of cases. This can be done by designing the cases with the same\nlevel of difficulty, familiarity, and applicability.\n\nSo while a chart was not necessary to support the author's points, I think it would have added a small but important summary point that the case study approach was successful and warranted the further development outlined in the concluding section.  \n\n\n\n\n\n\n\n\n\n\n### Additional software credits {.appendix}\n  \n- [`likert`](https://CRAN.R-project.org/package=likert)  for manipulating and plotting Likert-style data  \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}