[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I started doing data visualization work with an engineering education research group around 2008. The iterative process we developed to “find the story” in our data has been instrumental in shaping my approach to data graphics. You can read more about our research at https://midfield.online/.\nIt ain’t the cover of Rolling Stone, but a Sankey diagram I made was used to inform the cover art of the journal issue in which the article appeared, with the data graphic “enhanced” by their art department.\n\nMusic\nMy dad was a guitar player and taught me my first chords. I’ve been songwriting and performing since my teens. A favorite musical pilgrimage is the annual Swannanoa Gathering near Asheville, NC in late July. I’ve posted some draft tracks to SoundCloud.\n\nWork life\nI am a graduate of California State University, Northridge (1991), and the University of Washington (1993, 1995). I taught mechanical engineering courses at Rose-Hulman Institute of Technology from 2000-2020, co-authoring two books in that time.\n\nRetirement\nI retired from teaching in 2020 and spend my time doing songwriting, yard work, woodworking, R data graphics consulting, and opening doors for cats who give me doleful looks when a door fails to open on perpetual summer."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "For other matters graphical, I can be reached at\n\n\ngraphdoctor@gmail.com"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Stories",
    "section": "",
    "text": "Facets that are not small multiples\n\n\n\n\n\n\n\nggplot2\n\n\nR\n\n\n\n\nUsing the scales and space arguments of facet_grid() to manage panel heights of faceted charts when categories are not independent.\n\n\n\n\n\n\n2022-03-09\n\n\n\n\n\n\n  \n\n\n\n\nSurvey data I/O with likert\n\n\n\n\n\n\n\nR\n\n\n\n\nHow to prepare different forms of Likert-style survey data for the R likert package and edit the results to create 100% stacked-bar charts.\n\n\n\n\n\n\n2022-02-13\n\n\n\n\n\n\n  \n\n\n\n\nSurvey data chart designs\n\n\n\n\n\n\n\nR\n\n\nData storytelling\n\n\nEngineering education\n\n\n\n\nComparing chart designs for displaying Likert-style survey results and concluding that the 100% stacked-bar chart is the most effective.\n\n\n\n\n\n\n2022-02-12\n\n\n\n\n\n\n  \n\n\n\n\nPlot the variable of interest\n\n\n\n\n\n\n\nR\n\n\ndata storytelling\n\n\nengineering education\n\n\n\n\nA chart best serves its rhetorical purpose by directly illustrating the variables of interest discussed in the text.\n\n\n\n\n\n\n2022-02-03\n\n\n\n\n\n\n  \n\n\n\n\nStacked-bar alternatives\n\n\n\n\n\n\n\nR\n\n\ndata storytelling\n\n\nengineering education\n\n\n\n\nRedesigning two stacked bar charts to better convey the stories in their data.\n\n\n\n\n\n\n2022-01-14\n\n\n\n\n\n\n  \n\n\n\n\nThe missing relation\n\n\n\n\n\n\n\nR\n\n\ndata storytelling\n\n\nengineering education\n\n\n\n\nRedesigning a grouped-bar chart and including missing data to reveal an important change to the story in the data.\n\n\n\n\n\n\n2015-07-20\n\n\n\n\n\n\nNo matching items\n\nSoftware credits\n\n\nR and RStudio\ndata.table for manipulating data\n\nggplot2 for data graphics\n\nquarto for constructing this blog"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Open source licenses",
    "section": "",
    "text": "CC-BY 4.0 for text and images\n\nGPL-3 for code\n\nCC0 for data"
  },
  {
    "objectID": "posts/2015-07-20-the-missing-relation/index.html",
    "href": "posts/2015-07-20-the-missing-relation/index.html",
    "title": "The missing relation",
    "section": "",
    "text": "Summary\n\n\n\nIn redesigning a bar chart, I add data for context that shifts the focus of the story. I also correct a visual distortion by substituting a scatterplot for a bar chart that has a non-zero baseline.\nIn August 2007, Science published a bar graph that illustrates how design decisions made to attract a reader’s eye can also distort and conceal meaning. While the distortions were surely unintentional, the integrity of the story in the data was compromised nevertheless.\nA colleague and I noted the perceptual issues of this bar graph when the article first appeared. With the permission of the first author, Norm Fortenberry, we sent a shorter version of this critique to the Science editor. They responded by posting a scatterplot much like the one shown here in an online addendum.\nThroughout the post, you can click on the “R code” pointer to see the script used to create the graphs. This first code chunk loads the packages used."
  },
  {
    "objectID": "posts/2015-07-20-the-missing-relation/index.html#the-original-graph",
    "href": "posts/2015-07-20-the-missing-relation/index.html#the-original-graph",
    "title": "The missing relation",
    "section": "The original graph",
    "text": "The original graph\nThe graph shows a time series of retention rates for two cohorts of undergraduate students (Fortenberry et al. 2007). One cohort had matriculated in engineering in a First Year Engineering Program (FYEP) and one cohort had not (non-FYEP). The main story is clear, that retention rates drop over time for both cohorts but that FYEP students are always retained at a higher rate than non-FYEP students. Yet the graph design distorts one comparison and omits another.\n\n\n\nGraph from Science. Reprinted with permission from AAAS."
  },
  {
    "objectID": "posts/2015-07-20-the-missing-relation/index.html#visual-distortion",
    "href": "posts/2015-07-20-the-missing-relation/index.html#visual-distortion",
    "title": "The missing relation",
    "section": "Visual distortion",
    "text": "Visual distortion\nThe visual design distorts the relationship between the two cohorts. While the printed numbers show that the difference between the two cohorts remains fairly constant (about 10%) over time, the visual message conveyed by the bar heights is that the difference between cohorts increases over time. The FYEP bar is at first approximately 1/3 higher than the adjacent bar, then nearly twice as high, then more than three times as high.\n\n\nR code\n# read data from blog data directory\ndt <- fread(\"data/retention-2007.csv\")\n\n# grouped bar graph \n# use y = pct - 50 to force ggplot to produce a non-zero baseline \n# then relabel the y-axis scale, i.e., 0 is labeled 50%\nggplot(dt, aes(x = term, y = pct-50, color = status, fill = status)) +\n  geom_bar(stat = \"identity\", \n           position = position_dodge(), \n           width = 0.8, \n           color = \"black\") + \n  scale_x_continuous(breaks = c(3, 5, 7), \n                     labels = c(\"Third\", \"Fifth\", \"Seventh\"), \n                     expand = c(0.05, 0.15)) +\n  scale_y_continuous(limits = c(0, 40), \n                     breaks = seq(0, 40, 10), \n                     labels = c(\"50%\", \"60%\", \"70%\", \"80%\", \"90%\"), \n                     expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"gray80\", \"lightgoldenrod1\")) +\n  labs(x = \"Semester\", \n       y = \"Retention rate\") +\n  annotate(\"text\", \n           x = 0.1 + c(3, 5, 7), \n           y = -50 + c(85, 70, 62), \n           label = c(\"aprox. 1/3 higher\", \n                     \"approx. 2x higher\", \n                     \"more than\\n3x higher\"), \n           hjust = 0) + \n  theme_light() + \n  theme(legend.position = \"none\", \n        panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank())\n\n\n\n\n\nFigure 1: A non-zero baseline distorts the visual comparisons of bars.\n\n\n\n\nThe problem is the non-zero baseline—a well-known concern when using bar charts. Naomi Robbins reminds us that not all graphs require a zero baseline, contrary to Darrell Huff’s advice in his 1954 classic How to Lie with Statistics, but a bar graph without a zero baseline inevitably (and sometimes purposefully) exaggerates differences.\nThe caption reinforces the miscommunication by stating that the FYEP course “improved retention…into the third, fifth, and seventh semester,” subtly implying a difference that increases over time rather than remaining constant."
  },
  {
    "objectID": "posts/2015-07-20-the-missing-relation/index.html#data-structure",
    "href": "posts/2015-07-20-the-missing-relation/index.html#data-structure",
    "title": "The missing relation",
    "section": "Data structure",
    "text": "Data structure\nBecause the structure of a data set is an important factor in designing a chart, I classify the variables in Table 1.\n\n\n\n\nTable 1: Data structure\n\n\nvariable\nstructure\n\n\n\n\nterm\ncategorical, ordinal, discrete time, 3 levels\n\n\nstatus\ncategorical, nominal, 2 levels\n\n\npercent retention\nquantitative\n\n\n\n\n\n\nThe data are available in the blog data directory as a CSV file.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/retention-2007.csv\")"
  },
  {
    "objectID": "posts/2015-07-20-the-missing-relation/index.html#redesign",
    "href": "posts/2015-07-20-the-missing-relation/index.html#redesign",
    "title": "The missing relation",
    "section": "Redesign",
    "text": "Redesign\nA prominent element of this grouped-bar design is time on the horizontal axis, implying that time is the independent variable. Conventionally, time-dependent variables are best graphed as scatterplots with connected dots to display their evolution over time (Doumont 2009, 141). The difference between the two cohorts is clearly seen to be nearly constant.\n\n\nR code\n# redesign the bar chart as a scatterplot\nf <- ggplot(data = dt, mapping = aes(x = term, y = pct, fill = status)) +\n  \n  # helper line to almost connect the dots \n  geom_line(linetype = 2, color = \"gray60\") +\n  \n  # white point overprints the line\n  geom_point(size = 9, shape = 16, color = \"white\") +\n  \n  # data marker overprints the white space \n  geom_point(size = 3, shape = 16, color = \"black\") +\n  \n  # scales \n  scale_x_continuous(limits = c(1, 7), breaks = c(1, 3, 5, 7)) +\n  scale_y_continuous(limits = c(50, 100), breaks = seq(0, 100, 20)) + \n  labs(x = \"Semester\", y = \"Retention rate\") + \n  \n  # edit theme \n  theme_light() + \n  theme(legend.position = \"none\", \n        panel.grid = element_blank(), \n        axis.text = element_text(size = 11), \n        axis.title = element_text(size = 11))\n\n# print\nf\n\n\n\n\n\nFigure 2: Scatterplot of the numerical values in the original bar chart.\n\n\n\n\nHowever, a significant story in these data is (inadvertently) overlooked by omitting semester one, the point in time at which both cohorts would be considered 100% retained—the “missing relation” in the title. Only by including the starting time point can we see the importance of the early semesters.\nThe overlooked story is the early impact of the FYEP course with its higher rate of retention from semester 1 to 3. After semester 3, the factors affecting attrition seem to act on both groups equally—the lines are effectively parallel after semester 3. Thus the important impact of FYEP is in the first two terms. The visual story is clear when we include the missing term.\n\n\nR code\n# add the missing term 1 \nsem1 <- data.table(term = c(1, 1), status = c(\"fyep\", \"nonfyep\"), pct = c(100, 100))\ndt2 <- rbindlist(list(sem1, dt))\n\n# substitute data in the previous chart\ng <- f %+% dt2\ng\n\n\n\n\n\nFigure 3: Adding the first term in which both cohorts are at 100%.\n\n\n\n\nOne final design point: unlike a bar graph, a scatter plot does not require a zero baseline. However, I can include the full 0–100% range to display that the lowest rate of retention is still above 50%, an important result (as discussed in the prose of the article) compared to the retention rates of non-engineering disciplines. e.g., 42% in biological sciences and 30% in math and physical sciences.\n\n\nR code\n# start with the previous chart, replace the scale\nh <- g %+% \n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +\n  \n  # label the lines\n  annotate(\"text\", \n           x = c(4, 2), \n           y = c(85, 68), \n           label = c(\"FYEP students\\n(N = 2218)\", \"Non-FYEP students\\n(N = 2942)\"), \n           hjust = 0)\nh\n\n\n\n\n\nFigure 4: Providing a full scale on the y-axis."
  },
  {
    "objectID": "posts/2015-07-20-the-missing-relation/index.html#context",
    "href": "posts/2015-07-20-the-missing-relation/index.html#context",
    "title": "The missing relation",
    "section": "Context",
    "text": "Context\nMy critique to this point has focused on clarity and a minimalist design aesthetic, hallmarks of the “rhetoric of science” (Kostelnick 2008). However, recognizing that these downward sloping curves represent decisions made by real students invites us to ask about the human stories in these data. Are the students in either group better off? Are the students who leave engineering graduating in other disciplines? Is retention even a concern to students? In light of such questions, the graphs seem inadequate, as if we’ve missed an opportunity to tell important human stories.\nIn the text of the article, the authors do address such concerns. Retention rates reflect student decisions that are influenced almost exclusively by human factors: “student’s background, college administrative issues, academic and social integration, attitude and motivation, and fit within an institution.” Thus the retention data are a surrogate measure of some combination of these factors.\nThe original graph displays only six paired values (rate and semester). And though my redesigned graph corrects the distortions of the original, it still displays only eight paired values. Neither graph has the visual impact it might have had if designed to convey the important story the authors tell in their prose."
  },
  {
    "objectID": "posts/2022-01-14-stacked-bar-alternatives/index.html",
    "href": "posts/2022-01-14-stacked-bar-alternatives/index.html",
    "title": "Stacked-bar alternatives",
    "section": "",
    "text": "Summary\n\n\n\nThe rhetorical shortcomings of stacked-bar charts are overcome using alternative designs better suited for making visual comparisons. Both examples start as stacked-bar charts but end as different types, based on the variables to be shown and the messages to be conveyed.\nIn a recent article, the authors used two stacked bar charts to illustrate data on postdoctoral engineering PhDs (Main, Wang, and Tan 2021). The charts are truthful but not particularly informative—the visual logic of stacked bars tends to obscure rather than inform insight. By redesigning the charts, I hope to better align the logic of the visuals with the logic of the arguments.\nThe data in the article are summarized from the National Science Foundation’s (NSF) 1993–2013 Survey of Doctorate Recipients (SDR) and 1985–2013 Survey of Earned Doctorates (SED). I couldn’t find the original NSF annual data tables, so I approximated the values for my charts by measuring the lengths of bar segments in the original figures.\nMy purpose is not to find fault with the authors. Indeed, stacked bar charts like these are found throughout the NSF publications that report on the raw data. The authors can hardly be faulted for conforming to visual conventions sustained by the NSF."
  },
  {
    "objectID": "posts/2022-01-14-stacked-bar-alternatives/index.html#eliminating-the-trivial",
    "href": "posts/2022-01-14-stacked-bar-alternatives/index.html#eliminating-the-trivial",
    "title": "Stacked-bar alternatives",
    "section": "Eliminating the trivial",
    "text": "Eliminating the trivial\nThe original chart\nIn this chart, the authors display responses to the survey question “What was your primary reason for taking this postdoc?” by PhD completion year.\n\n\n\nOriginal Figure 2: Primary reasons for obtaining postdoctoral training among engineering PhDs: 1995–2011 (Main, Wang, and Tan 2021).\n\n\nData structure:\n\npercentage of respondents annually selecting reasons, quantitative variable\n\nreasons for postdoctoral training, nominal categorical variable, 6 levels\n\nyear of PhD completion, discrete ordinal categorical variable, 1995–2011\n\nThe data are available in the blog data directory as a CSV file.\nExploratory design: evolutions\nA prominent element of this stacked-bar design is time on the horizontal axis. A visual convention in this discourse community is that independent variables occupy horizontal axes, implying here that time is the independent variable. Conventionally, time-dependent variables are best graphed as scatterplots with connected dots to display their evolution over time (Doumont 2009, 141).\nThe figure below shows the stacked-bar data as a collection of evolutions—how survey percentages vary over time conditioned by the reason for obtaining postdoc training. The panels are organized in “graph order”, that is, increasing median value from left to right and from bottom to top (the panel median is shown as a horizontal reference line in each panel).\n\n\nR code\ndt <- fread(\"data/fig2.csv\")\n\ndt[, med_pct := median(pct), by = \"reason\"]\n\nggplot(data = dt, aes(x = year, y = pct)) +\n  geom_line(linetype = 2, color = \"gray\") +\n  geom_hline(aes(yintercept = med_pct), linetype = 3) + \n  geom_point() +\n  facet_wrap(vars(reorder(reason, pct, median)), ncol = 2, as.table = FALSE) +\n  labs(x = \"PhD completion year\", y = \"\")\n\n\n\n\n\nFigure 1: Graphing the data as a set of time-series.\n\n\n\n\nNo particular time-dependent trend stands out. However, two of the panels—Training in areas outside of PhD field and Other employment not available—appear to be inversely correlated. This made me wonder if and to what extent correlations exist.\nExploratory design: correlations\nOne approach to visualizing multivariate correlations is a scatterplot matrix, a grid of scatterplots of pairwise relationships (Emerson et al. 2013) as shown below. The lower triangle shows graphs of data taken two variables at a time with each data marker representing a year (the time variable is still present); the diagonal shows the distribution of each reason; and the upper triangle gives the pairwise Pearson correlation coefficients.\n\n\nR code\ndtwide <- copy(dt)\ndtwide <- dtwide[.(reason = c(\n  \"Additional training in PhD field\", \n  \"Training in areas outside of PhD field\", \n  \"Postdoc generally expected for career in this field\", \n  \"Work with a specific person or place\", \n  \"Other\", \n  \"Other employment not available\"), \n  to = c(\n    \"In field\", \n    \"Out of field\", \n    \"Expected\", \n    \"Specific\", \n    \"Other\", \n    \"Unavailable\")), \n  on = \"reason\", \n  reason := i.to]\n\ndtwide <- dcast(dtwide, year ~ reason, value.var = \"pct\", fill = 0)\n\n# https://stackoverflow.com/questions/30720455/how-to-set-same-scales-across-different-facets-with-ggpairs\nlowerfun <- function(data, mapping){\n  ggplot(data = data, mapping = mapping) +\n    geom_point() +\n    scale_x_continuous(limits = c(0, 45)) +\n    scale_y_continuous(limits = c(0, 45)) +\n    geom_smooth(formula = y ~ x, method = \"loess\", se = FALSE, size = 0.5)\n} \n\nggpairs(dtwide, \n        columns = 2:7, \n        upper = list(continuous = wrap(\"cor\", size = 3)), \n        lower = list(continuous = wrap(lowerfun))\n        )\n\n\n\n\n\nFigure 2: Looking for correlations.\n\n\n\n\nTwo variable pairs have correlation coefficients greater than 0.6, which for human behavior indicates a fairly strong correlation. Both are negative (inverse) correlations: one (that I noticed in the scatterplots) between “other employment unavailable” and “training outside the PhD field”; and a second between “expected in the field” and “other”. In the figure below. I extract both pairs of data to isolate the pairings.\n\n\nR code\nggpairs(dtwide, \n        columns = c(7, 5), \n        upper = list(continuous = wrap(\"cor\", size = 3)), \n        lower = list(continuous = wrap(lowerfun))\n        )\n\n\n\n\n\nFigure 3: Inverse correlation between “other employment unavailable” and “training outside the PhD field”.\n\n\n\n\n\n\nR code\nggpairs(dtwide, \n        columns = c(2, 4), \n        upper = list(continuous = wrap(\"cor\", size = 3)), \n        lower = list(continuous = wrap(lowerfun))\n        )\n\n\n\n\n\nFigure 4: Inverse correlation between “expected in the field” and “other”.\n\n\n\n\nThe messages appears to be that\n\nyears with a higher percentage of “Other employment not available” correlate with a lower percentage of “Training in areas outside of PhD field”, suggesting that when higher numbers of students accept postdoc positions because other employment is not to be found, they are not generally interested in obtaining new training outside their field.\nyears with a higher percentage of “Postdoc generally expected for career in this field” correlate to a lower percentage of “Other” reasons, which seems a reasonable if unremarkable result.\n\nMildly interesting, but not really compelling.\nFinal design: distributions\nThe evolution-assumption in the previous designs imposes an unnecessary barrier to finding stories in these data: time in this case is a prominent, but trivial, variable—the design emphasizes the trivial (Wainer 1997, 30).\nHaving the year in the data does not mean we have to use it. Ignoring time, I’m left with a data set comprising distributions of percentages conditioned by reason. For comparing distributions, the appropriate graph design is a box and whisker plot—the conventions of the box and whisker plot should be familiar to members of this discourse community.\n\n\nR code\nggplot(dt, aes(x = pct, y = reorder(reason, pct, median))) +\n  geom_boxplot(width = 0.6) +\n  labs(x = \"Percentage reasons cited, 1995-2011\", y = \"\") +\n  theme_light(base_size = 12) +\n  theme(legend.position = \"none\") \n\n\n\n\n\nFigure 5: Visual comparisons are more definitive once we eliminate the trivial (time) as the independent variable.\n\n\n\n\nHere the reasons are positioned from bottom to top in order of increasing median value. I conclude (as do the authors) that the top reason for accepting a postdoc position is additional training in field. The next three reasons have similar median values, so their ordering is less meaningful.\nBy comparing ranges and interquartile ranges (IQRs) I can draw a conclusion obscured by the previous designs. The range and IQR of “Additional training in PhD field” are noticeably less dispersed than the same measures of all other reasons. Thus in-field-training is both the most frequent reason and the least variable year to year–a conclusion that is hidden when we emphasize time dependence.\nLastly, with no legend to decode, the audience should find the redesign easier to interpret than the original. And from a publisher’s perspective, the new chart occupies less space on the page and does not have to be printed in color—less important for online documents, but important considerations for printed works.\nImpact\nIn discussing the stacked bar chart in the article, the authors state,\n\nThe most frequently indicated reasons for taking a postdoc after PhD completion were additional training in PhD field, additional training outside of PhD field, and postdoc training is generally expected for careers in their PhD field. The reasons that engineering PhDs provided for obtaining postdoc training fluctuates between 1995 and 2011.\n\nMy conclusions differ slightly from theirs and have a bit more nuance, though in neither case are the messages particularly compelling.\nNevertheless, the redesigned chart has an impact in serving its rhetorical goal better than the original. What one sees in the chart and what one reads in the text are more closely aligned than in the original. As Tufte (1997, 53) writes,\n\n…if displays of data are to be truthful and compelling, the design logic of the display must reflect the intellectual logic of the analysis…"
  },
  {
    "objectID": "posts/2022-01-14-stacked-bar-alternatives/index.html#making-visual-comparisons",
    "href": "posts/2022-01-14-stacked-bar-alternatives/index.html#making-visual-comparisons",
    "title": "Stacked-bar alternatives",
    "section": "Making visual comparisons",
    "text": "Making visual comparisons\nThe original chart\nIn this chart, the authors provide a “descriptive summary of the relationship between postdoctoral training and subsequent career outcomes 7–9 years after PhD completion.”\n\n\n\nOriginal Figure 3: Percentage of non-postdocs and postdocs by employment sector and primary work activity 7-9 years after PhD completion, 1993-2013. (Main, Wang, and Tan 2021).\n\n\nData structure (Figure 3a)\n\npercentage of respondents in an employment sector, quantitative variable\n\nemployment sectors, nominal categorical variable, 5 levels\n\npostdoc status, nominal categorical variable, 2 levels\n\nData structure (Figure 3b)\n\npercentage of respondents in a work activity, quantitative variable\n\nprimary work activity, nominal categorical variable, 5 levels\n\npostdoc status, nominal categorical variable, 2 levels\n\nThe data are available in the blog data directory as a CSV file.\nRedesign: dot chart\nStacked bars of this type, like pie charts, show fractions of a whole. Such charts are a “good choice for lay audiences, but they certainly lack the accuracy of alternative representations” (Doumont 2009, 134). Such data are often best encoded using dot charts—charts with dots along a common scale (Cleveland 1984).\n\n\nR code\ndt <- fread(\"data/fig3.csv\")\n\ndt3a <- dt[type %chin% c(\"Employment sector\")]\ndt3a[, sector := type_levels]\ndt3a[, type := NULL]\ndt3a[, type_levels := NULL]\n\ndt3b <- dt[type %chin% c(\"Primary work activity\")]\ndt3b[, activity := type_levels]\ndt3b[, type := NULL]\ndt3b[, type_levels := NULL]\n\ndt3b <- dt3b[.(activity = c(\n  \"Research and development\", \n  \"Teaching\", \n  \"Management and admin\", \n  \"Computer applications\", \n  \"Other\"), \n  to = c(\n    \"Res & dev\", \n    \"Teaching\", \n    \"Mgmt & admin\", \n    \"Computer apps\", \n    \"Other\")), \n  on = \"activity\", \n  activity := i.to]\n\n\nIn the original stacked bar chart, the authors have one column for each postdoc status level, indicating the rhetorical goal of comparing the experiences of PhDs with postdocs to those without. This lends itself to plotting the dots for postdocs and non-postdocs along the same row of the chart, facilitating a direct visual comparison.\nBelow, the employment sector graph is redesigned as a dot chart with rows ordered from bottom to top in order of increasing mean percentage.\n\n\nR code\nggplot(dt3a, aes(x = fraction, y = reorder(sector, fraction, mean), color = status, fill = status)) +\n  geom_point(size = 3, shape = 21) +\n  labs(x = \"Percentage\", \n       y = \"\", \n       title = \"Employment sector\") +\n  theme_light(base_size = 12) +\n  theme(legend.title = element_blank()) + \n  scale_color_manual(values = c(\"black\", \"black\")) + \n  scale_fill_manual(values = c(\"white\", \"black\")) +\n  scale_x_continuous(limits = c(0, 60), breaks = seq(0, 100, 10))\n\n\n\n\n\nFigure 6: Quantitative comparisons are visually more accessible when data are plotted along a common horizontal scale.\n\n\n\n\nIn discussing the stacked bar chart in the article, the authors state,\n\nMost postdoctoral scholars and non-postdocs worked in industry 7–9 years after the PhD. However, the share of PhDs who worked in industry is lower among the postdoc group compared to non-postdocs. Compared with non-postdocs, a greater share of postdocs go on to tenure-track and non-tenure-track faculty positions.\n\nThe argument is also supported by the dot chart but qualitative terms “most”, “lower”, etc. could be replaced with quantitative comparisons. For example, the dot chart supports the argument that industry employs just over 40% of postdocs and more than 50% of non-postdocs. Moreover, industry employs twice the number of postdocs than the next most popular sector (tenure-track), and more than three times the number of non-postdocs.\nA similar outcome can be seen in the redesigned work activity chart.\n\n\nR code\nggplot(dt3b, aes(x = fraction, y = reorder(activity, fraction, mean), color = status, fill = status)) +\n  geom_point(size = 3, shape = 21) +\n  labs(x = \"Percentage\", \n       y = \"\", \n       title = \"Primary work activity \") +\n  theme_light(base_size = 12) +\n  theme(legend.title = element_blank()) + \n  scale_color_manual(values = c(\"black\", \"black\")) + \n  scale_fill_manual(values = c(\"white\", \"black\")) +\n  scale_x_continuous(limits = c(0, 60), breaks = seq(0, 100, 10))\n\n\n\n\n\nFigure 7: Dot charts are superior to stacked-bar charts for audiences expecting visual access to quantitative comparisons.\n\n\n\n\nIn discussing the stacked bar chart in the article, the authors state,\n\nCompared with non-postdocs, a greater proportion of postdoctoral scholars engage in research and development as their primary work activity. Meanwhile, a greater proportion of non-postdocs perform management and administrative duties.\n\nAgain, the discussion is also consistent with the new chart but a quantitative comparison is easier to see: research and development employs over 40% of non-postdocs and over 50% of postdocs, which for both groups is at least four times the number in the next most popular sector (teaching).\nImpact\nDot charts are superior to stacked bar charts for data of this type. As illustrated above, relative magnitudes are more easily visualized and quantified than with stacked bars. Even if one prefers not to include quantities in the verbal discussion, readers can easily make quantitative inferences on their own.\nAlso, in this particular case, the dot chart legend is much easier to decode, with two entries compared to 5 entries for the original stacked bars."
  },
  {
    "objectID": "posts/2022-01-14-stacked-bar-alternatives/index.html#recognizing-conventional-grip",
    "href": "posts/2022-01-14-stacked-bar-alternatives/index.html#recognizing-conventional-grip",
    "title": "Stacked-bar alternatives",
    "section": "Recognizing conventional grip",
    "text": "Recognizing conventional grip\nI mentioned in the introduction that NSF reports from which some of these data were obtained sustain the visual convention of stacked bar charts even though the stacked-bar design is deficient compared to alternative designs available. This persistence of convention highlights what Kostelnick and Hassett call the tenacity of conventional grip (2003, 171). They write,\n\nReaders become highly invested in the status quo because it cuts a well-worn path, and deviations from that familiar path can seem arduous, risky, and unnecessary. The well-worn path can give sanction to conventuional practices that seem to violate perceptual principles of effective design…once readers have acquired a knack for reading these conventions, readers become quite proficient and may strongly resist wandering off that path.\n\nHowever, conventional grip can create problems for both authors and audiences (ibid., 182),\n\nAlthough grip can greatly benefit users by creating a stable environment for shaping and interpreting visual language, conventions can also become so entrenched that they interfere with meaning making by not changing to match conditions or by leading to mindless, unwarranted conformity. Designers can easily succumb to conventional inertia and perhaps not even realize its rhetorical drawbacks."
  },
  {
    "objectID": "posts/2022-02-01-plot-the-variable-of-interest/index.html",
    "href": "posts/2022-02-01-plot-the-variable-of-interest/index.html",
    "title": "Plot the variable of interest",
    "section": "",
    "text": "Summary\n\n\n\nI redesign a stacked-bar chart to attempt to better align the logic of the display with the logic of the argument. The visual structure of the redesigned chart suggests a concomitant reorganization of the prose, illustrating the interplay between visual and verbal rhetoric.\nIn a 2021 article, the authors summarize 134 engineering-curricula articles for teachers of pre-college students. The authors classify the articles by grade level and the type of engineering inquiry (Purzer, Quintana-Cifuentes, and Menekse 2021).\nIn section 7, the authors include a data table of numbers of articles by grade level and inquiry type. A stacked-bar chart represents the numbers in the table. In supporting their argument, however, the authors cite ratios of these values—ratios that might be inferred, but are not directly displayed, in the chart provided.\nI take the text to represent the authors’ intended message and look for ways to more effectively represent that message visually.\nMy intention is not to critique the article as a whole, which develops a “honeycomb of engineering” research framework for examining how engineering concepts and practices are taught at pre-college levels. I focus instead on the interplay between data, argument, and charts in one section only.\nThe R code for the post is listed under the “R code” pointers."
  },
  {
    "objectID": "posts/2022-02-01-plot-the-variable-of-interest/index.html#data-structure",
    "href": "posts/2022-02-01-plot-the-variable-of-interest/index.html#data-structure",
    "title": "Plot the variable of interest",
    "section": "Data structure",
    "text": "Data structure\nIn the original Table 2, the authors classify 134 articles by grade level and the type of engineering inquiry. These are the raw numbers they cite in their discussion. The parenthetical titles in the column heading are the journals in which the articles appear.\n\n\n\n(original Table 2) The distribution of the number of articles by engineering inquiry and grade level band. (Purzer, Quintana-Cifuentes, and Menekse 2021.)\n\n\nBecause the structure of a data set is an important factor in designing a chart, I classify the variables in Table 1. The multiway dot chart was designed specifically for data of this type: one quantitative variable depending on two independent categorical variables (Cleveland 1993, 302).\n\n\n\n\nData structure\n\n\nvariable\nstructure\n\n\n\n\nnumber of published articles\nquantitative\n\n\ntype of engineering inquiry\ncategorical, nominal, 6 levels\n\n\ngrade level\ncategorical, ordinal, 3 levels\n\n\n\n\n\n\nThe data are available in the blog data directory as a CSV file.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/honeycomb-2021.csv\")\n\n# order the levels of grade level\ndt <- dt[, grade_level := factor(grade_level, levels = c(\"Elementary School\", \"Middle School\", \"High School\"))]\n\n# compute percentage of articles by grade level\ndt[, pct_level := round(N / N_level * 100, 0)]\n\n# obtain the total N of articles\narticle_total <- sum(dt$N)"
  },
  {
    "objectID": "posts/2022-02-01-plot-the-variable-of-interest/index.html#limitations-of-stacked-bars",
    "href": "posts/2022-02-01-plot-the-variable-of-interest/index.html#limitations-of-stacked-bars",
    "title": "Plot the variable of interest",
    "section": "Limitations of stacked bars",
    "text": "Limitations of stacked bars\nThe original Figure 3 is a conventional stacked-bar representation of the numbers in Table 2. The authors improve on the usual default software settings by ordering the rows of the chart from top to bottom by increasing totals.\n\n\n\n(original Figure 3) The representation of the six engineering inquiries as three grade-level bands published in the three NSTA journals between 2005 and 2019 (Purzer, Quintana-Cifuentes, and Menekse 2021.)\n\n\nThe perceptual limitations of stacked-bar charts are well-known: visual comparisons are effective for quantities having a common baseline and are ineffective otherwise.\n\nStacked bars work well when you want to compare totals across different categories, and then within a given category, you want some understanding of the subcomponent pieces. Notice though, that they work less well if you want to compare those subcomponent pieces across categories. This is because as soon as you get past the first series, you no longer have a consistent baseline to use to compare. This is a harder comparison for our eyes to make, so something to keep in mind when reaching for stacked bars. —Cole Nussbaumer Knaflic (2017)"
  },
  {
    "objectID": "posts/2022-02-01-plot-the-variable-of-interest/index.html#whats-your-point",
    "href": "posts/2022-02-01-plot-the-variable-of-interest/index.html#whats-your-point",
    "title": "Plot the variable of interest",
    "section": "What’s your point?",
    "text": "What’s your point?\nReferring to the stacked-bar chart (original Figure 3) and the data table (original Table 2), the authors state,\n\nA total of 134 articles that made explicit connections to engineering, included sufficient details on design challenges and engineering problems, and were labeled as engineering lessons (see Figure 3). Table 2 presents the frequency of these categories across three grade-level bands. Of the 134 articles, 63 (47%) were published at the elementary level in Science & Children, 51 (38%) in Science Scope representing the middle school, and 20 (15%) in The Science Teacher at the high school level.\n\nThe original Figure 3 does not reflect the logic of this argument. The stacked-bar chart visually compares article totals by type of inquiry and (as Knaflic says) offers some “understanding of the sub-component pieces,” but neither of these arguments are made in the text.\nSo what’s the point of the chart?\n\nWhat’s your point? Seriously, that’s the most important question to ask when creating a data visualization. —Stephanie Evergreen (2021)\n\nIf the point of the chart is to illustrate the three percentages mentioned in the text (15%, 38%, and 47%), then a combined bar chart and table would serve.\n\n\nR code\n# aesthetic assignments across charts\ntext_col_x      <- 105\ntheme_text_size <- 11\ngeom_text_size  <- 4\ngeom_point_size <- 3.5\nbar_fill        <- \"#C2A5CF\" # light purple\ngray_text       <- \"#636363\"\n\n# subset selected data for this chart\nsel <- dt[, .(grade_level, N_level)]\nsel <- unique(sel)\n\n# basic bar chart\np <- ggplot(data = sel, mapping = aes(x = N_level, y = grade_level)) +\n  geom_bar(stat = \"identity\", width = 0.7, fill = bar_fill) +\n  scale_x_continuous(limits = c(-10, text_col_x)) +\n  coord_cartesian(clip = \"off\") +\n  labs(x = \"\", y = \"\")\n\n# edit theme \np <- p + \n  theme_minimal() +\n  theme(panel.grid  = element_blank(), \n        axis.text.x = element_blank(), \n        axis.text.y = element_text(size = theme_text_size), \n        plot.title  = element_text(size = theme_text_size, face = \"plain\", hjust = 0))\n\n# column of percentages\np <- p + \n  geom_text(aes(x = -5, y = reorder(grade_level, N_level), label = paste0(round(100 * N_level/article_total, 0), \"%\")), \n            hjust = 1, color = gray_text, size = geom_text_size)\n\n# column of N\np <- p + \n  geom_text(aes(x = text_col_x, y = reorder(grade_level, N_level), label = N_level), \n            hjust = 1, color = gray_text, size = geom_text_size)\n\n# total N\np <- p + \n  geom_text(x = text_col_x, y = 0, label = paste0(\"Total: \", article_total), \n            hjust = 1, color = gray_text, size = geom_text_size)\n\n# print the chart\np\n\n\n\n\n\nFigure 1: Number of articles by grade level, 2005-2019.\n\n\n\n\nIn this design, based on (Doumont 2009, 135), bars are drawn horizontally so the labels are easily read. Combined with the tabulated numbers, a scale is unnecessary. To respect the proportion among the data, bars are shown in full (starting at zero). Because grade level is an ordinal category (ordered levels), I order the rows in “graph order,” that is, with increasing grade level from bottom to top.\nIn contrast, if the point of the original chart is to compare totals by type of inquiry—which the original figure supports but the text neglects—then a similar chart-table could be used. Because inquiry type is a nominal category (unordered levels), rows are ordered by the number of articles by type.\n\n\nR code\nggplot(data = dt, mapping = aes(x = N, y = reorder(inquiry, N_inquiry))) +\n  geom_bar(stat = \"identity\", width = 0.75, fill = bar_fill) +\n  scale_x_continuous(limits = c(-10, text_col_x)) +\n  coord_cartesian(clip = \"off\") +\n  labs(x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(panel.grid  = element_blank(), \n        axis.text.x = element_blank(), \n        axis.text.y = element_text(size = theme_text_size), \n        plot.title  = element_text(size = theme_text_size, face = \"plain\", hjust = 0)) + \n\n  # column of percentages\n  geom_text(aes(x     = -5, \n                y     = reorder(inquiry, N_inquiry), \n                label = paste0(round(100 * N_inquiry/article_total, 0), \"%\")), \n            hjust = 1, color = gray_text) + \n  \n  # column of N\n  geom_text(aes(x = text_col_x, y = reorder(inquiry, N_inquiry), label = N_inquiry), \n            hjust = 1, color = gray_text, size = geom_text_size) +\n  \n  # total N\n  geom_text(x = text_col_x, y = 0, label = paste0(\"Total: \", article_total), \n            hjust = 1, color = gray_text, size = geom_text_size)\n\n\n\n\n\nFigure 2: Number of articles by type of engineering inquiry, 2005-2019.\n\n\n\n\nBoth of my suggested charts avoid the limitations of the stacked-bar chart and both support specific—and different—arguments. A short paragraph comparing grade levels is quite distinct from one comparing inquiry types. Deciding which to use (or both) depends on the point(s) you want to make. The text is not clear on what point the original figure is making."
  },
  {
    "objectID": "posts/2022-02-01-plot-the-variable-of-interest/index.html#interplay-between-chart-and-argument",
    "href": "posts/2022-02-01-plot-the-variable-of-interest/index.html#interplay-between-chart-and-argument",
    "title": "Plot the variable of interest",
    "section": "Interplay between chart and argument",
    "text": "Interplay between chart and argument\nFollowing the paragraph quoted earlier, the article goes on to compare different ratios of numbers from the data table, with paragraphs organized around inquiry type. For example, the Design-Build-Test (DBT) discussion begins with,\n\nThe DBT model was observed across all grade levels. These types of lessons and design projects were most popular at the elementary level, featured in 75% (47 of 63) of engineering lessons published at this grade level band, followed by 67% (34 of 51) at the middle-school level and 50% (10 of 20) at the high school level. In the DBT engineering lessons… [continues with project examples]\n\nHere the variable of interest is the “popularity” of DBT as a percentage of articles in a grade level band. In this next chart, I compare the stated percentages visually.\n\n\nR code\n# subset selected data for this chart\nsel <- dt[abbr == \"(DBT)\", .(grade_level, N, N_level, pct_level)]\n\nggplot(data = sel, mapping = aes(x = pct_level, y = grade_level)) +\n  geom_point(size = geom_point_size) +\n  scale_x_continuous(limits = c(0, 80), breaks = seq(0, 100, 10), expand = c(0, 0)) +\n  labs(x = \"Fraction of N articles at grade level (%)\", y = \"\", title = \"Design-Build-Test\") +\n  \n  # edit theme\n  theme_light() +\n  theme(axis.text  = element_text(size = theme_text_size),\n        plot.title = element_text(size = theme_text_size, face = \"plain\", hjust = 0), \n        panel.grid.minor = element_blank()) + \n\n  # total N per row\n  geom_text(aes(x = 1, y = grade_level, label = paste0(\"(N = \", N_level, \")\")),\n            hjust = 0, color = gray_text, size = geom_text_size)\n\n\n\n\n\nFigure 3: Comparing fraction of DBT articles at three grade levels.\n\n\n\n\nThe perceptual difficulty I have with this chart is that each row is a percentage of a different N. Conventionally, a comparison of percentages are based on a common denominator. Yet the chart accurately reflects the argument in the text—my perceptual difficulty with the chart suggests an underlying difficulty in the argument.\nWe encounter the same difficulty with the original stacked-bar chart. Visually, the DBT segments are shown as components of the DBT bar. Verbally, the DBT segments are discussed as percentages of sums of segments across all bars.\nThis is not to say there is anything wrong with the argument—only that the logic of the argument is not reflected in the design logic of the chart.\nChart redesign\nI designed Figure 4 to better reflect the intellectual logic of the argument by plotting percentages of grade-level articles in the same panel. Thus all values in a panel have the same denominator and the percentages in a panel sum to 100%. Consistent with the data structure, the basic design (as expected) is a multiway dot chart.\nTo compare key values across panels, I used color to highlight the three inquiries the grade-level bands have in common. Rows and panels are in graph order. The small bar charts along the side of the multiway chart show the relative proportions of N for each row and their sum is given at the bottom of each column. The names of the source journals are included in the panel headings.\n\n\nR code\n# subset for this chart, percentages set to NA don't print\nsel <- dt[pct_level == 0, pct_level := NA]\nsel[, level_journal := paste0(grade_level, \" (\", journal, \")\")]\n\n# plot 1: multiway dot plot\nplot1 <- ggplot(data = sel, mapping = aes(x = pct_level, y = reorder(inquiry, N_inquiry))) +\n  geom_point(size = geom_point_size, shape = 21, fill = \"white\") +\n  facet_wrap(vars(reorder(level_journal, unclass(grade_level))), ncol = 1, as.table = FALSE) +\n  scale_x_continuous(limits = c(0, 80), breaks = seq(0, 100, 10), expand = c(0, 0)) +\n  coord_cartesian(clip = \"off\") + \n  labs(x = \"Percentage of articles by grade level\", y = \"\") +\n  theme_light() +\n  theme(panel.grid.minor = element_blank(), \n        axis.text        = element_text(size = theme_text_size),\n        strip.background = element_blank(), \n        strip.text  = element_text(size = theme_text_size, color = \"black\", face = \"plain\", hjust = 0),\n        plot.title  = element_text(size = theme_text_size, face = \"plain\", hjust = 0), \n        # top, right, bottom, and left\n        plot.margin = unit(c(0, 0, 0, 0), \"mm\")) +\n  \n  # overprint the top three inquiry dots\n  geom_point(data = sel[abbr == \"(DBT)\"], shape = 21, fill = \"#1b9e77\", size = geom_point_size) + \n  geom_point(data = sel[abbr == \"(UCD)\"], shape = 21, fill = \"#d95f02\", size = geom_point_size) + \n  geom_point(data = sel[abbr == \"(ENS)\"], shape = 21, fill = \"#7570b3\", size = geom_point_size)\n\n# plot 2: bar chart on the side\nplot2 <- ggplot(data = sel, mapping = aes(x = N, y = reorder(inquiry, N_inquiry))) +\n  geom_bar(stat = \"identity\", width = 0.75, fill = bar_fill) +\n  facet_wrap(vars(grade_level), ncol = 1, as.table = FALSE) +\n  scale_x_continuous(limits = c(-20, max(sel$N))) +\n  coord_cartesian(clip = \"off\") + \n  labs(x = \"\", y = \"\", title =) +\n  \n  # edit theme\n  theme_light() +\n  theme(panel.grid = element_blank(), \n        axis.ticks = element_blank(), \n        panel.border = element_blank(), \n        axis.text.x = element_text(color = \"white\"),\n        axis.text.y = element_blank(), \n        strip.background = element_blank(), \n        strip.text = element_text(color = \"white\"),\n        # margins top, right, bottom, and left\n        plot.margin = unit(c(0, 0, 0, -5), \"mm\")) +\n\n  # \"N\" at the top of column\n  annotate(\"text\", x = -5, y = 7.25, label = \"N\", hjust = 1, color = gray_text, size = geom_text_size) +\n  \n  # column of N\n  geom_text(aes(x = -5, y = reorder(inquiry, N_inquiry), label = N),\n            hjust = 1, color = gray_text, size = geom_text_size) +\n  \n  # short line under column of numbers\n  geom_segment(aes(x = -20, y = 0.45,  xend = -0.8, yend = 0.45), color = gray_text) +\n  \n  # sum of N per level\n  geom_text(aes(x = -5, y = 0, label = N_level), hjust = 1, color = gray_text, size = geom_text_size)\n\n# combine the two plots\ncowplot::ggdraw() +\n  draw_plot(plot1, x = 0, y = 0, width = 0.8, height = 1) +\n  draw_plot(plot2, x = 0.82, y = 0, width = 0.18, height = 1)\n\n\n\n\n\nFigure 4: Popularity of inquiry type by grade-level band. Color indicates inquiries the grade levels have in common. Bars show relative number of articles by row.\n\n\n\n\nThe important feature of this design is that the majority of the percentages compared in the original text are visually compared in the figure. It also conveys all the textual information from the original data table.\nLike the missing entries in the original data table, missing inquiry types are easy to spot by the absence of a data marker. (In a strict sense, these are not missing data; the actual values are zero—as shown in the numerical columns of the side bar-charts.)\nWe can also see that the top three types of inquiry have the same rank order in all grade levels. The bar charts help us recognize the extent to which the top two inquiry types dominate the literature.\nn An added rhetorical advatage of this design to potential audiences such as pre-college teachers or creators of pre-college engineering materials is the snapshot it provides of the state of their area of interest.\nLastly, that the organization of the chart is visually more effective suggests that a reorganization of the argument could also be more effective. The primary organization of the chart is by grade-level band. If I were to align the logic of the argument with the logic of the display, then the text too would be organized by grade-level band. For example, I might start the discussion as follows:\n The elementary school grade level had only three types of inquiry but the highest number of articles overall (N = 63). DBT is by far the largest portion of articles (75%) with UCD (21%) and ENS (4%) making up the rest.\nCompared to the elementary level, the middle school level had nearly as many articles (N = 51) and the same top three inquiry types. But with more inquiry types, the top three inquiries comprised smaller percentages of the whole: DBT (67%), UCD (18%), ENS (6%). Middle school is also the only level in which all six inquiry types are present.\nIn contrast, the high school level … etc. \nAligning visual rhetoric and verbal rhetoric in this fashion can be an important aid to a reader trying to follow the discussion. Moreover, this process can be an important aid to an authorial team in developing their message in the first place. The iterative interplay between constructing a chart and constructing an argument—between visual rhetoric and verbal rhetoric—is one of the most important aspects of data visualization."
  },
  {
    "objectID": "posts/2022-02-12-survey-data-chart-designs/index.html",
    "href": "posts/2022-02-12-survey-data-chart-designs/index.html",
    "title": "Survey data chart designs",
    "section": "",
    "text": "Summary\n\n\n\nI reconstruct three alternative chart designs for Likert-style survey data from a 2018 post by Lisa Charlotte Muth and Gregor Aisch and share the source data and my R code. Comparing the charts in light of their arguments, I agree that the 100% stacked-bar chart is the more effective of the three designs.\nFor a recent presentation, I needed to graph the results of a Likert-style survey.\nIn the past I tended to use the diverging stacked-bar design by Robbins and Heiberger (2011; 2014). Browsing for alternatives, I found the essays by Stephen Few (2016) and Lisa Charlotte Muth and Gregor Aisch (2018) to be well-reasoned and useful.\nIn this post, I reconstruct the three chart designs from Muth and Aisch with two goals in mind: to reproduce and comment on the comparisons they make using a data set of my choosing; and to share the source data and my R code.\nHere, however, I do not discuss the R code in any detail. In a companion post, I focus on R for preparing different forms of source data for the likert package and editing the results for publication-ready charts.\nI primarily use data.table, ggplot2, and likert R packages. An appealing feature of likert is its compatibility with data.table and ggplot2 functionality. Note that to reproduce this work, likert must be at least version 1.3.6.\nThe R code for the post is listed under the “R code” pointers."
  },
  {
    "objectID": "posts/2022-02-12-survey-data-chart-designs/index.html#data",
    "href": "posts/2022-02-12-survey-data-chart-designs/index.html#data",
    "title": "Survey data chart designs",
    "section": "Data",
    "text": "Data\nThe practice data in my example are from an engineering education article by Ashanthi Maxworth (2021), selected because the data are compact and the survey includes a Neutral option. The table from the original article is shown below. There were 31 respondents.\n\n\n\n(Original Table 3) Percentage student responses for each question in the feedback form.\n\n\nSurvey data are most likely to be reported in one of three forms: summary percentages (as above), summary counts, or row-records. The likert() function accepts any of these forms as input. The practice data, in all three forms, are available in the blog data directory in CSV files, though for this post I will use the summary count form only.\nRead the prepared data file in summary count form.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/case-study-2021-count.csv\")\n\n\n\n\n\n\n\n\nq_no\nstr_disagree\ndisagree\nneutral\nagree\nstr_agree\n\n\n\n\nQ1\n2\n0\n8\n12\n9\n\n\nQ2\n2\n2\n7\n14\n6\n\n\nQ3\n1\n1\n5\n9\n15\n\n\nQ4\n0\n2\n10\n12\n7\n\n\nQ5\n2\n0\n6\n11\n12\n\n\n\n\n\n\nI rename the first column Item, and the data frame is ready to input to the likert() function. Because my goal is comparing chart designs, I’m not interested in the specific survey questions, so I leave the question labels in their abbreviated form (Q1, Q2, …).\n\n\nR code\n# rename first column\nsetnames(dt, \"q_no\", \"Item\", skip_absent = TRUE)\n\n# examine the result\ndt[]\n\n\n     Item str_disagree disagree neutral agree str_agree\n   <char>        <int>    <int>   <int> <int>     <int>\n1:     Q1            2        0       8    12         9\n2:     Q2            2        2       7    14         6\n3:     Q3            1        1       5     9        15\n4:     Q4            0        2      10    12         7\n5:     Q5            2        0       6    11        12\n\n\nThe salient characteristics of the data frame are:\n\nOne row per question\nFirst column is named Item and contains the question labels\nRemaining columns are named for the opinion levels in increasing order left to right\nColumn values are the counts of respondents choosing that option\nThe sum of row counts is the number of respondents answering that question"
  },
  {
    "objectID": "posts/2022-02-12-survey-data-chart-designs/index.html#diverging-stacked-bars",
    "href": "posts/2022-02-12-survey-data-chart-designs/index.html#diverging-stacked-bars",
    "title": "Survey data chart designs",
    "section": "Diverging stacked bars",
    "text": "Diverging stacked bars\nA defining feature of the divergent stacked-bar is that the Neutral segment is split half to the left and half to the right of the zero reference line. Also, because each row of the data table sums to 100%, each bar of the chart has a horizontal length of 100%, partitioned to show the component percentages.\n\n\nR code\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# set scale limits to fill the data rectangle\nmy_limits <- c(-25, 86)\n\n# recode the opinion options\nsetnames_opinion_labels(likert_list$results)\n\n# create the chart\nplot(likert_list, \n     centered = TRUE,              # diverging\n     include.center  = TRUE,       # neutral included\n     plot.percent.low     = FALSE,\n     plot.percent.neutral = FALSE,\n     plot.percent.high    = FALSE) +\n  \n  # additional ggplot components\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     labels = abs(my_breaks)) +\n  my_theme_elements +\n  my_hline\n\n\n\n\n\nFigure 1: Diverging stacked-bar design\n\n\n\n\nThe top-down row order is by decreasing agreement totals (Agree + Strongly Agree). In contrast, by Heiberger and Robbins’ definition, the row position of Q2 and Q4 would be swapped so that the maximum endpoint monotonically decreases top to bottom.\nDescribing a diverging stacked bar chart, Robbins and Heiberger say,\n\nIt is difficult to compare lengths without a common baseline. In this situation, we are primarily interested in the total percent to the right or left of the zero line; the breakdown into strongly or not is of lesser interest so that the primary comparisons do have a common baseline of zero (Robbins and Heiberger 2011, 1060).\n\nI agree—if we assume the Neutrals can treated as half positive and half negative. Muth and Aisch point out that we have no way of knowing that this is true. Because being truthful is a first principle of ethical data visualization, this assumption makes me uneasy. A lot depends on how the survey questions are worded and how the people surveyed interpret the Neutral response. In this specific case, I’m not certain the Neutrals can treated as half positive and half negative. Thus, the zero reference line does not establish a common baseline and we lose the ability to make effective visual comparisons.\nWe can recover the common baseline at zero by moving Neutral to a side chart of its own."
  },
  {
    "objectID": "posts/2022-02-12-survey-data-chart-designs/index.html#neutral-on-the-side",
    "href": "posts/2022-02-12-survey-data-chart-designs/index.html#neutral-on-the-side",
    "title": "Survey data chart designs",
    "section": "Neutral on the side",
    "text": "Neutral on the side\nBy removing the Neutral responses, the zero reference line is a common baseline for visually comparing total agreement. We can see that the top-down row order is by decreasing agreement totals (Agree + Strongly Agree). And for a given row, we can visually compare total disagreement to total agreement.\n\n\nR code\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# set scale limits to fill the data rectangle\nmy_limits <- c(-13, 78)\n\n# recode the opinion options\nsetnames_opinion_labels(likert_list$results)\n\n# extract Neutrals for second chart\nlikert_list_neutral <- likert_list$results[, .(Item, Neutral)]\n\n# delete Neutrals from likert list (removing neutral from legend)\nlikert_list$results[, Neutral := NULL]\nlikert_list$levels  <- likert_list$levels[!likert_list$levels %in% \"neutral\"]\nlikert_list$nlevels <- likert_list$nlevels - 1\n\n# create the chart\nplot1 <- plot(likert_list, \n              centered = TRUE,               # diverging\n              plot.percent.low     = FALSE,\n              plot.percent.neutral = FALSE,\n              plot.percent.high    = FALSE) +\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     labels = abs(my_breaks), \n                     expand = c(0, 0)) +\n  my_theme_elements +\n  my_hline\n\n# display\nplot1\n\n\n\n\n\nFigure 2: Diverging stacked bar, neutral omitted.\n\n\n\n\nNext I construct the second part of the chart (using ggplot2 functions only) to plot the Neutral responses alone.\n\n\nR code\n# use Neutral data frame from earlier\nlikert_list <- likert_list_neutral\n\n# set scale limits to fill the data rectangle\nmy_limits <- c(0, 33)\n\n# extract order of questions (factors) from previous chart object\nfactor_levels <- levels(plot1$data$Item)\n\n# factors for ordering rows \nlikert_list[, Item := factor(Item, levels = factor_levels)]\n\n# assign a variable to fill by and create a legend\nlikert_list[, opinion := \"Neutral\"]\n\n# create the chart\nplot2 <- ggplot(data = likert_list, mapping = aes(x = Neutral, y = Item, fill = opinion)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"\", y = \"\") +\n  scale_x_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     expand = c(0, 0)) +\n  scale_fill_manual(values = neutral_color) +\n  my_theme_elements +\n  my_vline\n  \n# display\nplot2\n\n\n\n\n\nFigure 3: Neutral responses only.\n\n\n\n\nI combine the two charts and adjust their proportions to make equal scale divisions the same length.\n\n\nR code\n# edit Neutral bar chart aesthetics before combining \nplot2 <- plot2 +\n  theme(axis.text.y = element_blank(), \n        legend.justification = -0.25)\n\n# set plot proportions by trial and error until scales match\nwidth_1 <- 0.71\nwidth_2 <- 1 - width_1\n\n# combine plots \nggdraw() +\n  draw_plot(plot1, x = 0      , y = 0, width = width_1, height = 1) +\n  draw_plot(plot2, x = width_1, y = 0, width = width_2, height = 1)\n\n\n\n\n\nFigure 4: Diverging stacked bar chart with neutral on the side.\n\n\n\n\n\nDesigned in this way, differences between positive and negative results now stand out a bit more, the sum of Agree and Strongly Agree are easier to read, and the Neutral values are both easier to read and compare (Few 2016).\n\nAs Muth and Aisch point out, this design gives a good idea of the “competition” between agreement and disagreement. In this case, across all questions more than 60% of the respondents agreed and in all but one instance fewer than 10% disagreed.\nIn addition, between 15-30% responded Neutral. We don’t know if that means “I don’t know” or “I have no opinion” or “Sometimes I agree and sometimes I don’t”or “I’m tired of answering Likert-style surveys” or something else—which is a very good reason to graph Neutral on the side.\nI like this design."
  },
  {
    "objectID": "posts/2022-02-12-survey-data-chart-designs/index.html#stacked-bars",
    "href": "posts/2022-02-12-survey-data-chart-designs/index.html#stacked-bars",
    "title": "Survey data chart designs",
    "section": "100% stacked bars",
    "text": "100% stacked bars\nThe final of the three designs is the 100% stacked bar—which until now I have not considered as effective as diverging stacked-bars at conveying survey results. What makes the difference today is Muth and Aisch’s suggestion to add a secondary scale along the top of the chart—a simple and elegant contribution.\n\n\nR code\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# set scale limits\nmy_limits <- c(0, 100)\n\n# recode the opinion options\nsetnames_opinion_labels(likert_list$results)\n\n# create the chart\nplot(likert_list, \n     centered = FALSE,              # 100% stacked bars\n     include.center  = TRUE,        # include neutral\n     plot.percent.low     = FALSE,\n     plot.percent.neutral = FALSE,\n     plot.percent.high    = FALSE) +\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     sec.axis = sec_axis( # second scale\n                       trans = function(z) z - 100, \n                       breaks = my_breaks, \n                       labels = as.character(abs(my_breaks)))) +\n  my_theme_elements +\n  my_hline\n\n\n\n\n\nFigure 5: 100% stacked bar chart.\n\n\n\n\nWith the right boundary as a baseline, I read the top scale for agreement percentages; with the left boundary as a baseline, I read the bottom scale for disagreement percentages. We can easily quantify a comparison between strong opinions (outer left and outer right) or between total agreement and total disagreement. Neither of the divergent stacked-bar charts allow this level of direct visual access (though the bar segments could be directly labeled with their respective percentages).\nLike the previous chart, the rationale for ordering the rows is clear—the agreement total monotonically increase from bottom to top. Of lesser importance, this design also immediately communicates that the bar segments are parts of a whole—that each bar represents 100% of responses.\nThe only disadvantage of this chart compared to the previous one is that the relative proportions of the Neutral responses are harder to compare. Neutrals are important data but the main story is usually a comparison between people who have opinions—that is, the bar segments to the left and right of the Neutral center.\nI have to agree with Muth and Aisch—this is an effective design."
  },
  {
    "objectID": "posts/2022-02-12-survey-data-chart-designs/index.html#back-to-the-story",
    "href": "posts/2022-02-12-survey-data-chart-designs/index.html#back-to-the-story",
    "title": "Survey data chart designs",
    "section": "Back to the story",
    "text": "Back to the story\nWere I to prepare this chart to accompany the original article, I might label the rows with shortened forms of the questions and cite the full questions in the text or in the data table. (Alternatively, likert() does have an argument to help manage longer question text.)\n\n\nR code\ndt_story <- copy(dt)\n\n# recode the opinion options\nsetnames_opinion_labels(dt_story)\n\n# recode the question labels\ndt_story[, Item := question_labels]\n\n# create the likert list\nlikert_list <- likert(summary = dt_story)\n\n# set scale limits\nmy_limits  <- c(0, 100)\n\n# create the chart\nplot(likert_list, \n     centered = FALSE, \n     include.center  = TRUE, \n     plot.percent.low     = FALSE,\n     plot.percent.neutral = FALSE,\n     plot.percent.high    = FALSE) +\n  scale_y_continuous(limits = my_limits, \n                     breaks = my_breaks, \n                     sec.axis = sec_axis( # second scale\n                       trans = function(z) z - 100, \n                       breaks = my_breaks, \n                       labels = as.character(abs(my_breaks)))) +\n  my_theme_elements +\n  my_hline\n\n\n\n\n\nFigure 6: Editing the legend key and question labels for readability.\n\n\n\n\nAs an example of the results discussion in the article, the “provide facts” paragraph states,\n\nIn the third feedback question, 24 out of 31 students (77.4%) agreed that the case study motivated them to provide facts such as calculations and simulations to support their answers. Unlike a typical textbook problem where there is a definite answer, making an argument in a case study requires thinking beyond the material delivered in class. Therefore, the use of additional calculations and especially simulations were needed to support the argument (Maxworth 2021).\n\nThis is a perfectly straightforward description of the result and the chart supports the argument visually. In terms of the larger narrative, however, the chart provides a rationale for revising the narrative framework—instead of discussing the results in question order (Q1, Q2, …), discuss the results in order of level of agreement (highest to lowest), supported visually by the row order in the chart (top to bottom).\nI think the chart provides evidence for an additional assertion: that the preponderance of responses are positive,\n\nBetween 61-77% of responses were positive over the full range of survey statements.\nThe largest negative response was to the Analyze errors/misconceptions assertion at 13% (4 out of 31 responses); all other negatives were at 6.5% (2 of 31).\n\nGiven the overall positive response, the small number of negatives may have resulted from a mismatch between a student and the case they selected. As the author states in their conclusion,\n\nIn future implementations, an effort is needed to balance the choice distribution of cases. This can be done by designing the cases with the same level of difficulty, familiarity, and applicability.\n\nSo while a chart was not necessary to support the author’s points, I think it would have added a small but important summary point that the case study approach was successful and warranted the further development outlined in the concluding section."
  },
  {
    "objectID": "posts/2022-02-13-survey-data-io/index.html",
    "href": "posts/2022-02-13-survey-data-io/index.html",
    "title": "Survey data I/O with likert",
    "section": "",
    "text": "Summary\n\n\n\nGiven Likert-style survey data in one of three common forms, I shape the data to suit the input requirements of the likert R package and use the output to create 100% stacked-bar charts. In each case, I illustrate two routine revision tasks: editing the question labels on the bars and editing the opinion levels in the legend.\nThis post is a tutorial on how to prepare different forms of Likert-style survey data for the R likert package and using its output to create 100% stacked-bar charts. I focus on preparing the data for likert() input and editing its output for the final chart. For exploring the package functionality more fully, I recommend the tutorials by Laura Mudge (2019) and Jake Chanenson (2021).\nIn a companion post I develop the R script for constructing the 100% stacked-bar chart and discuss the rationale for selecting it as a more effective design for Likert-style survey data.\nI use data.table, ggplot2, and likert R packages. An appealing feature of likert is its compatibility with data.table and ggplot2 functionality. Note that to reproduce this work, likert must be at least version 1.3.6 (currently the development version).\nThe R code for the post is listed under the “R code” pointers."
  },
  {
    "objectID": "posts/2022-02-13-survey-data-io/index.html#data",
    "href": "posts/2022-02-13-survey-data-io/index.html#data",
    "title": "Survey data I/O with likert",
    "section": "Data",
    "text": "Data\nThe practice data in my example are from an engineering education article by Ashanthi Maxworth (2021), selected because the data are compact and the survey includes a Neutral option. The table from the original article is shown below. There were 31 respondents.\n\n\n\n(Original Table 3) Percentage student responses for each question in the feedback form.\n\n\nSurvey data are most likely to be reported in one of three forms: summary percentages (as above), summary counts, or row-records. The likert() function accepts any of these forms as input. The practice data, in all three forms, are available in the blog data directory as CSV files.\n\nsummary counts\n\nsummary percentages\n\nrow-records"
  },
  {
    "objectID": "posts/2022-02-13-survey-data-io/index.html#summary-counts",
    "href": "posts/2022-02-13-survey-data-io/index.html#summary-counts",
    "title": "Survey data I/O with likert",
    "section": "Summary counts",
    "text": "Summary counts\nRead the prepared data file in summary count form.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/case-study-2021-count.csv\")\n\n\n\n\n\n\n\n\nq_no\nstr_disagree\ndisagree\nneutral\nagree\nstr_agree\n\n\n\n\nQ1\n2\n0\n8\n12\n9\n\n\nQ2\n2\n2\n7\n14\n6\n\n\nQ3\n1\n1\n5\n9\n15\n\n\nQ4\n0\n2\n10\n12\n7\n\n\nQ5\n2\n0\n6\n11\n12\n\n\n\n\n\n\n\nlikert() input\nI rename the first column Item for consistency with the likert() function.\n\n\nR code\n# rename first column\nsetnames_Item(dt)\n\n# examine the result\ndt[]\n\n\n     Item str_disagree disagree neutral agree str_agree\n   <char>        <int>    <int>   <int> <int>     <int>\n1:     Q1            2        0       8    12         9\n2:     Q2            2        2       7    14         6\n3:     Q3            1        1       5     9        15\n4:     Q4            0        2      10    12         7\n5:     Q5            2        0       6    11        12\n\n\nThe likert() function accepts input data frames having this structure. The salient characteristics are:\n\none row per question\nfirst column is named Item and contains the question labels\nremaining columns are named for the opinion levels in increasing order left to right\ncolumn values are the counts of respondents choosing that option\nthe sum of row counts is the number of respondents answering that question\n\n\n\nlikert() output\nTo operate on this data frame, we assign it to the summary argument of the likert() function. The result is a list of various statistics about the Likert-style data. Note that the results output preserves the data.table structure of the input.\n\n\nR code\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# examine its structure\nstr(likert_list)\n\n\nList of 5\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item        : chr [1:5] \"Q1\" \"Q2\" \"Q3\" \"Q4\" ...\n  ..$ str_disagree: num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ disagree    : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ neutral     : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ agree       : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ str_agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   : NULL\n $ grouping: NULL\n $ nlevels : num 5\n $ levels  : chr [1:5] \"str_disagree\" \"disagree\" \"neutral\" \"agree\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nThe components of the list are:\n\nresults\n\nData frame. Percentage of responses by question, opinion level, and group.\n\nitems\n\nData frame. Copy of original row-record input (NULL in this example).\n\ngrouping\n\nCopy of original grouping vector that subsets results (NULL in this example).\n\nnlevels\n\nInteger. Number of opinion levels used in the calculations.\n\nlevels\n\nCharacter. Ordered vector of opinion level labels.\n\n\n\n\n\nBasic chart\nTo use this list to create a chart, we assign it as the first argument of the plot() function.\n\n\nR code\n# create the basic chart (default digits = 0 throws an error)\nplot(likert_list, digits = 1)\n\n\n\n\n\nFigure 1: Default chart design from likert().\n\n\n\n\n\n\n100% stacked bar chart\nThe same list can be used to create a 100% stacked-bar chart by assigning it as the first argument of likert_100_pct_bar()—a function (defined at the top of the post) that wraps likert.plot and sets the likert arguments and ggplot2 functions that produce my preferred design.\n\n\nR code\n# customize the chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 2: Summary-count data, 100% stacked-bar chart.\n\n\n\n\n\n\nLegend key\nThe legend key is edited via the column names of likert_list$results. Viewing its column names,\n\n\nR code\nnames(likert_list$results)\n\n\n[1] \"Item\"         \"str_disagree\" \"disagree\"     \"neutral\"      \"agree\"       \n[6] \"str_agree\"   \n\n\nUsing a vector of opinion labels defined at the top of the post, I rename the opinion columns of the data frame.\n\n\nR code\n# recode the opinion options \nsetnames_opinion_labels(likert_list$results)\n\n# examine the result\nstr(likert_list)\n\n\nList of 5\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item             : chr [1:5] \"Q1\" \"Q2\" \"Q3\" \"Q4\" ...\n  ..$ Strongly Disagree: num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ Disagree         : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ Neutral          : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ Agree            : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ Strongly Agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   : NULL\n $ grouping: NULL\n $ nlevels : num 5\n $ levels  : chr [1:5] \"str_disagree\" \"disagree\" \"neutral\" \"agree\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nThe change can be seen in the structure above and in the revised figure.\n\n\nR code\n# create the chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 3: Editing the legend key.\n\n\n\n\n\n\nQuestion labels\nThe question labels are edited via the values in the Item column of likert_list$results. Viewing the first column in vector form,\n\n\nR code\nlikert_list$results[[\"Item\"]]\n\n\n[1] \"Q1\" \"Q2\" \"Q3\" \"Q4\" \"Q5\"\n\n\nUsing a vector of question labels defined at the top of the post, I substitute them for the values in the original Item column.\n\n\nR code\n# recode the question labels\nlikert_list$results[, Item := question_labels]\n\n# examine the result\nstr(likert_list)\n\n\nList of 5\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item             : chr [1:5] \"Beyond the content\" \"Analyze errors\" \"Provide facts\" \"Develop writing\" ...\n  ..$ Strongly Disagree: num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ Disagree         : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ Neutral          : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ Agree            : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ Strongly Agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   : NULL\n $ grouping: NULL\n $ nlevels : num 5\n $ levels  : chr [1:5] \"str_disagree\" \"disagree\" \"neutral\" \"agree\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nAgain, the change is seen in the structure above and in the revised figure.\n\n\nR code\n# create the chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 4: Editing the question labels.\n\n\n\n\nThis approach is somewhat ad-hoc, but works as long as you are careful to write the substitutions in the correct order. If I were programming these steps, I would create additional tables (as in a database) and join the substitutions by clearly assigned key variables.\n\n\nOr edit the labels first\nAlternatively one can produce the same result by editing the opinion labels and question labels of the initial data frame before submitting it to likert(). The row and column structure reflects the changes.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/case-study-2021-count.csv\")\n\n# rename columns\nsetnames_Item(dt)\nsetnames_opinion_labels(dt)\n\n# recode the question labels\ndt[, Item := question_labels]\n\n# examine the result\ndt[]\n\n\n                   Item Strongly Disagree Disagree Neutral Agree Strongly Agree\n                 <char>             <int>    <int>   <int> <int>          <int>\n1:   Beyond the content                 2        0       8    12              9\n2:       Analyze errors                 2        2       7    14              6\n3:        Provide facts                 1        1       5     9             15\n4:      Develop writing                 0        2      10    12              7\n5: Independent learning                 2        0       6    11             12\n\n\nThe likert list that results is nearly identical to the previous version except the levels vector uses the new opinion labels.\n\n\nR code\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# examine the result\nstr(likert_list)\n\n\nList of 5\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item             : chr [1:5] \"Beyond the content\" \"Analyze errors\" \"Provide facts\" \"Develop writing\" ...\n  ..$ Strongly Disagree: num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ Disagree         : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ Neutral          : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ Agree            : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ Strongly Agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   : NULL\n $ grouping: NULL\n $ nlevels : num 5\n $ levels  : chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nR code\n# create the chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 5: Summary-count data, editing labels before invoking likert()."
  },
  {
    "objectID": "posts/2022-02-13-survey-data-io/index.html#summary-percentages",
    "href": "posts/2022-02-13-survey-data-io/index.html#summary-percentages",
    "title": "Survey data I/O with likert",
    "section": "Summary percentages",
    "text": "Summary percentages\nRead the prepared data file in summary percentage form. The percentages are directly from the table in the source article. Like before, I rename the first column Item for consistency with the likert() function.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/case-study-2021-percent.csv\")\n\n# rename first column\nsetnames_Item(dt)\n\n\n\n\n\n\n\n\nItem\nstr_disagree\ndisagree\nneutral\nagree\nstr_agree\n\n\n\n\nQ1\n6.5\n0.0\n25.8\n38.7\n29.0\n\n\nQ2\n6.5\n6.5\n22.6\n45.2\n19.4\n\n\nQ3\n3.2\n3.2\n16.1\n29.0\n48.4\n\n\nQ4\n0.0\n6.5\n32.3\n38.7\n22.6\n\n\nQ5\n6.5\n0.0\n19.4\n35.5\n38.7\n\n\n\n\n\n\n\nOption 1: Convert percentages to counts\nThis option is the most direct approach, assuming we know the number of respondents to each question. In this example we do (though this is not always the case). In this case study we have 31 respondents and all respondents replied to all the questions.\n\n\nR code\n# number of respondents in this example\nN_respondents <- 31\n\n# identify the numeric columns\nsel_cols <- names(dt)[sapply(dt, is.numeric)]\n\n# convert percentages to integer counts\ndt[, c(sel_cols) := lapply(.SD, function(x) round(N_respondents * x/100, 0)), .SDcols = sel_cols]\n\n\n\n\n\n\n\n\nItem\nstr_disagree\ndisagree\nneutral\nagree\nstr_agree\n\n\n\n\nQ1\n2\n0\n8\n12\n9\n\n\nQ2\n2\n2\n7\n14\n6\n\n\nQ3\n1\n1\n5\n9\n15\n\n\nQ4\n0\n2\n10\n12\n7\n\n\nQ5\n2\n0\n6\n11\n12\n\n\n\n\n\n<>\nThis data structure is identical to the one we worked with in the previous section, so we know how to work with it.\n\n\nOption 2: Use percentages as-is\nThis option might be necessary if we do not know the number of respondents replying to each question. Start by reading the data file and again rename the first column Item for consistency with the likert() function.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/case-study-2021-percent.csv\")\n\n# rename first column\nsetnames_Item(dt)\n\n\n\n\n\n\n\n\nItem\nstr_disagree\ndisagree\nneutral\nagree\nstr_agree\n\n\n\n\nQ1\n6.5\n0.0\n25.8\n38.7\n29.0\n\n\nQ2\n6.5\n6.5\n22.6\n45.2\n19.4\n\n\nQ3\n3.2\n3.2\n16.1\n29.0\n48.4\n\n\nQ4\n0.0\n6.5\n32.3\n38.7\n22.6\n\n\nQ5\n6.5\n0.0\n19.4\n35.5\n38.7\n\n\n\n\n\n\nWith one row per question, the row percentages should sum to 100%. They do, but with an error due to rounding in the reported percentages.\n\n\nR code\n# check row totals of numeric columns\nsel_cols <- names(dt)[sapply(dt, is.numeric)]\nrow_sum  <- rowSums(dt[, .SD, .SDcols = sel_cols])\n\n# examine result\ndt[, row_total := row_sum]\ndt[, rounding_error := row_sum - 100]\ndt[, .(Item, row_total, rounding_error)]\n\n\n     Item row_total rounding_error\n   <char>     <num>          <num>\n1:     Q1     100.0            0.0\n2:     Q2     100.2            0.2\n3:     Q3      99.9           -0.1\n4:     Q4     100.1            0.1\n5:     Q5     100.1            0.1\n\n\nIf we ignore the rounding error, it can introduce small but noticeable errors in the bar lengths in the chart. A simple remediation is to subtract the small errors from the neutral columns so that all rows sum to 100% exactly. The adjusted Neutrals are shown below.\n\n\nR code\n# subtract error from neutral\ndt[, adjusted_neutral := neutral - rounding_error]\n\n# examine the result\ndt[, .(Item, neutral, rounding_error, adjusted_neutral)]\n\n\n     Item neutral rounding_error adjusted_neutral\n   <char>   <num>          <num>            <num>\n1:     Q1    25.8            0.0             25.8\n2:     Q2    22.6            0.2             22.4\n3:     Q3    16.1           -0.1             16.2\n4:     Q4    32.3            0.1             32.2\n5:     Q5    19.4            0.1             19.3\n\n\n\n\nlikert() input\nReplacing neutral with the adjusted neutral and deleting the temporary information columns yields the data structure I need for the summary percentage form:\n\n\nR code\n# adjust neutral\ndt[, neutral := adjusted_neutral]\n\n# delete temporary information columns\ndt[, c(\"row_total\", \"rounding_error\", \"adjusted_neutral\") := NULL]\n\n# examine the result\ndt[]\n\n\n     Item str_disagree disagree neutral agree str_agree\n   <char>        <num>    <num>   <num> <num>     <num>\n1:     Q1          6.5      0.0    25.8  38.7      29.0\n2:     Q2          6.5      6.5    22.4  45.2      19.4\n3:     Q3          3.2      3.2    16.2  29.0      48.4\n4:     Q4          0.0      6.5    32.2  38.7      22.6\n5:     Q5          6.5      0.0    19.3  35.5      38.7\n\n\nData structure:\n\none row per question\nfirst column is named Item and contains the question labels\nremaining columns are named for the opinion levels in increasing order left to right\ncolumn values are the percentages of respondents choosing that option\nthe sum of row percentages is exactly 100%\n\nTo prepare the data frame for graphing, I use the “edit the labels first” approach described earlier.\n\n\nR code\n# recode the opinion options\nsetnames_opinion_labels(dt)\n\n# recode the question labels\ndt[, Item := question_labels]\n\n# examine the result\ndt[]\n\n\n                   Item Strongly Disagree Disagree Neutral Agree Strongly Agree\n                 <char>             <num>    <num>   <num> <num>          <num>\n1:   Beyond the content               6.5      0.0    25.8  38.7           29.0\n2:       Analyze errors               6.5      6.5    22.4  45.2           19.4\n3:        Provide facts               3.2      3.2    16.2  29.0           48.4\n4:      Develop writing               0.0      6.5    32.2  38.7           22.6\n5: Independent learning               6.5      0.0    19.3  35.5           38.7\n\n\n\n\nlikert() output\nTo operate on this data frame, we again use the summary argument of likert(). The result is a list similar to that produced when we operated on summary counts and the same familiar chart.\n\n\nR code\n# create the likert list\nlikert_list <- likert(summary = dt)\n\n# examine its structure\nstr(likert_list)\n\n\nList of 5\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item             : chr [1:5] \"Beyond the content\" \"Analyze errors\" \"Provide facts\" \"Develop writing\" ...\n  ..$ Strongly Disagree: num [1:5] 6.5 6.5 3.2 0 6.5\n  ..$ Disagree         : num [1:5] 0 6.5 3.2 6.5 0\n  ..$ Neutral          : num [1:5] 25.8 22.4 16.2 32.2 19.3\n  ..$ Agree            : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ Strongly Agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   : NULL\n $ grouping: NULL\n $ nlevels : num 5\n $ levels  : chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nR code\n# 100% stacked bar chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 6: Summary-percentage data, 100% stacked-bar chart."
  },
  {
    "objectID": "posts/2022-02-13-survey-data-io/index.html#row-records",
    "href": "posts/2022-02-13-survey-data-io/index.html#row-records",
    "title": "Survey data I/O with likert",
    "section": "Row records",
    "text": "Row records\nIn row-record form, everything we want to know about an individual is in one row, that is, a row-record for that individual. Thus the number of rows equals the number of respondents.\nI made up a practice data set in row-record form with 31 rows and 6 columns. These are fictitious data I designed specifically to have the same summary characteristics as the published summary data used earlier.\nRead the prepared data file in row-record form and view the data frame.\n\n\nR code\n# read observed data\ndt <- fread(\"data/case-study-2021-row-record.csv\")\n\n# examine the result\ndt[]\n\n\n      obs    Q1    Q2    Q3    Q4    Q5\n    <int> <int> <int> <int> <int> <int>\n 1:     1     3     4     3     4     4\n 2:     2     5     1     5     3     5\n 3:     3     5     5     4     5     4\n 4:     4     3     4     5     4     5\n 5:     5     4     4     5     2     4\n 6:     6     4     3     5     3     4\n---                                    \n26:    26     5     5     5     4     5\n27:    27     5     2     3     4     1\n28:    28     3     4     5     3     5\n29:    29     3     3     4     3     4\n30:    30     4     4     5     3     1\n31:    31     4     4     5     5     5\n\n\nThe first column is a fictitious respondent ID. The remaining columns represent responses to the survey questions. For basic charts like those shown here, all columns should be question responses, so I delete the ID. Though I don’t cover it here, additional non-question columns are allowed for grouping the results. See, for example, (Mudge 2019).\n\n\nR code\n# delete the ID column\ndt[, obs := NULL]\n\n# examine the result\ndt[]\n\n\n       Q1    Q2    Q3    Q4    Q5\n    <int> <int> <int> <int> <int>\n 1:     3     4     3     4     4\n 2:     5     1     5     3     5\n 3:     5     5     4     5     4\n 4:     3     4     5     4     5\n 5:     4     4     5     2     4\n 6:     4     3     5     3     4\n---                              \n26:     5     5     5     4     5\n27:     5     2     3     4     1\n28:     3     4     5     3     5\n29:     3     3     4     3     4\n30:     4     4     5     3     1\n31:     4     4     5     5     5\n\n\n\nlikert() input\nFor the likert() function to accept data in this form, all question response columns must be factors with identical sets of levels. Reformatting the columns and checking the structure yields,\n\n\nR code\n# reformat columns as factors\nsel_cols <- names(dt)\ndt[, c(sel_cols) := lapply(.SD, function(x) factor(x, levels = 1:5)), .SDcols = sel_cols]\n\n# examine the result\ndt[]\n\n\n        Q1     Q2     Q3     Q4     Q5\n    <fctr> <fctr> <fctr> <fctr> <fctr>\n 1:      3      4      3      4      4\n 2:      5      1      5      3      5\n 3:      5      5      4      5      4\n 4:      3      4      5      4      5\n 5:      4      4      5      2      4\n 6:      4      3      5      3      4\n---                                   \n26:      5      5      5      4      5\n27:      5      2      3      4      1\n28:      3      4      5      3      5\n29:      3      3      4      3      4\n30:      4      4      5      3      1\n31:      4      4      5      5      5\n\n\nInput data structure\n\nOne row per respondent. The number of rows equals the number of respondents.\nOne column per question. The column name is the question label. The number of columns equals the number of survey questions.\n\nEach column is a factor with an identical set of levels. The number of levels equals the number of answer options in the survey.\nColumn values are the encoded opinions of the respondent: 1 (Strongly Disagree), 2 (Disagree), 3 (Neutral), etc.\n\n\n\nlikert() output\nTo operate on a row-record data frame, we assign it to the items argument of the likert() function. The result is again a list.\nHowever, unlike the previous output lists, the data.table structure of the input has not been preserved. I use data.table syntax in subsequent operations, so I convert both results and items to data.tables.\n\n\nR code\n# create likert list \nlikert_list <- likert(items = dt)\n\n# convert output data frames to data.tables\nsetDT(likert_list$results)\nsetDT(likert_list$items)\n\n# examine the result\nstr(likert_list)\n\n\nList of 6\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item: chr [1:5] \"Q1\" \"Q2\" \"Q3\" \"Q4\" ...\n  ..$ 1   : num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ 2   : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ 3   : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ 4   : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ 5   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   :Classes 'data.table' and 'data.frame':  31 obs. of  5 variables:\n  ..$ Q1: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 3 5 5 3 4 4 3 1 4 5 ...\n  ..$ Q2: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 1 5 4 4 3 2 5 5 4 ...\n  ..$ Q3: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 3 5 4 5 5 5 4 4 4 5 ...\n  ..$ Q4: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 3 5 4 2 3 4 3 5 5 ...\n  ..$ Q5: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 5 4 5 4 4 4 3 4 3 ...\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ grouping: NULL\n $ factors : NULL\n $ nlevels : int 5\n $ levels  : chr [1:5] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nThe components of the list are:\n\nresults\n\nData frame. Percentage of responses by question, opinion level, and group.\n\nitems\n\nData frame. Copy of original row-record input.\n\ngrouping\n\nCopy of original grouping vector that subsets results (NULL in this example).\n\nfactors\n\nCopy of original vector matching columns to factors (NULL in this example).\n\nnlevels\n\nInteger. Number of opinion levels used in the calculations.\n\nlevels\n\nCharacter. Ordered vector of opinion level labels.\n\n\n\n\nDraft chart\nWith row-record data, the plot function requires both results and items from the output list. The chart is familiar, but the opinion labels are now the integers used to encode the survey results.\n\n\nR code\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 7: Row-record data, 100% stacked-bar chart.\n\n\n\n\n\n\nLegend key\nAs before, the legend key is edited via the column names of likert_list$results. Note the corresponding changes in the likert list and chart.\n\n\nR code\n# recode the opinion options\nsetnames(likert_list$results, \n         old = as.character(1:5), \n         new = opinion_labels, \n         skip_absent = TRUE)\n\n# examine the result\nstr(likert_list)\n\n\nList of 6\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item             : chr [1:5] \"Q1\" \"Q2\" \"Q3\" \"Q4\" ...\n  ..$ Strongly Disagree: num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ Disagree         : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ Neutral          : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ Agree            : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ Strongly Agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   :Classes 'data.table' and 'data.frame':  31 obs. of  5 variables:\n  ..$ Q1: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 3 5 5 3 4 4 3 1 4 5 ...\n  ..$ Q2: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 1 5 4 4 3 2 5 5 4 ...\n  ..$ Q3: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 3 5 4 5 5 5 4 4 4 5 ...\n  ..$ Q4: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 3 5 4 2 3 4 3 5 5 ...\n  ..$ Q5: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 5 4 5 4 4 4 3 4 3 ...\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ grouping: NULL\n $ factors : NULL\n $ nlevels : int 5\n $ levels  : chr [1:5] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nR code\n# create the chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 8: Row-record data, editing the legend key.\n\n\n\n\n\n\nQuestion labels\nWith row-record data, both results and items data frames must be revised to edit the question labels. Note the corresponding changes in the likert list and chart.\n\n\nR code\n# recode Item column of $results\nlikert_list$results[, Item := question_labels]\n\n# recode column names of $items\nsetnames(likert_list$items, \n         old = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"), \n         new = question_labels, \n         skip_absent = TRUE)\n\n# examine the result\nstr(likert_list)\n\n\nList of 6\n $ results :Classes 'data.table' and 'data.frame':  5 obs. of  6 variables:\n  ..$ Item             : chr [1:5] \"Beyond the content\" \"Analyze errors\" \"Provide facts\" \"Develop writing\" ...\n  ..$ Strongly Disagree: num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ Disagree         : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ Neutral          : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ Agree            : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ Strongly Agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ items   :Classes 'data.table' and 'data.frame':  31 obs. of  5 variables:\n  ..$ Beyond the content  : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 3 5 5 3 4 4 3 1 4 5 ...\n  ..$ Analyze errors      : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 1 5 4 4 3 2 5 5 4 ...\n  ..$ Provide facts       : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 3 5 4 5 5 5 4 4 4 5 ...\n  ..$ Develop writing     : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 3 5 4 2 3 4 3 5 5 ...\n  ..$ Independent learning: Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 4 5 4 5 4 4 4 3 4 3 ...\n  ..- attr(*, \".internal.selfref\")=<externalptr> \n $ grouping: NULL\n $ factors : NULL\n $ nlevels : int 5\n $ levels  : chr [1:5] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nR code\n# create the chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 9: Row-record data, editing the question labels.\n\n\n\n\n\n\nOr edit the labels first\nAs before, we have an alternative approach: one can produce the same result by editing the opinion labels and question labels of the data frame before submitting it to likert(). Question labels are substituted for the column names. Opinion levels (as text) are substituted for the encoded integers, i.e., 1 = Strongly Disagree through 5 = Strongly Agree.\nTo illustrate, I start with a fresh row-record data set.\n\n\nR code\n# read prepared data\ndt <- fread(\"data/case-study-2021-row-record.csv\")\n\n# delete the ID column\ndt <- subset(dt, select = -c(obs))\n\n# recode the question labels in the column names\nsetnames(dt, \n         old = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"), \n         new = question_labels, \n         skip_absent = TRUE)\n\n# recode integer values with opinion options  \nsel_cols <- names(dt)\ndt[, (sel_cols) := lapply(.SD, function(x) fcase(\n  x == 1, opinion_labels[1],\n  x == 2, opinion_labels[2],\n  x == 3, opinion_labels[3],\n  x == 4, opinion_labels[4],\n  x == 5, opinion_labels[5])),\n  .SDcols = sel_cols]\n\n# convert columns to factors  \ndt <- dt[, lapply(.SD, function(x) factor(x, levels = opinion_labels)), .SDcols = sel_cols]\n\n# examine the result\ndt[]\n\n\n    Beyond the content    Analyze errors  Provide facts Develop writing\n                <fctr>            <fctr>         <fctr>          <fctr>\n 1:            Neutral             Agree        Neutral           Agree\n 2:     Strongly Agree Strongly Disagree Strongly Agree         Neutral\n 3:     Strongly Agree    Strongly Agree          Agree  Strongly Agree\n 4:            Neutral             Agree Strongly Agree           Agree\n 5:              Agree             Agree Strongly Agree        Disagree\n 6:              Agree           Neutral Strongly Agree         Neutral\n---                                                                    \n26:     Strongly Agree    Strongly Agree Strongly Agree           Agree\n27:     Strongly Agree          Disagree        Neutral           Agree\n28:            Neutral             Agree Strongly Agree         Neutral\n29:            Neutral           Neutral          Agree         Neutral\n30:              Agree             Agree Strongly Agree         Neutral\n31:              Agree             Agree Strongly Agree  Strongly Agree\n    Independent learning\n                  <fctr>\n 1:                Agree\n 2:       Strongly Agree\n 3:                Agree\n 4:       Strongly Agree\n 5:                Agree\n 6:                Agree\n---                     \n26:       Strongly Agree\n27:    Strongly Disagree\n28:       Strongly Agree\n29:                Agree\n30:    Strongly Disagree\n31:       Strongly Agree\n\n\nInput to likert() produces the familiar chart.\n\n\nR code\n# create the likert list\nlikert_list <- likert(items = dt)\n\n# examine the result\nstr(likert_list)\n\n\nList of 6\n $ results :'data.frame':   5 obs. of  6 variables:\n  ..$ Item             : chr [1:5] \"Beyond the content\" \"Analyze errors\" \"Provide facts\" \"Develop writing\" ...\n  ..$ Strongly Disagree: num [1:5] 6.45 6.45 3.23 0 6.45\n  ..$ Disagree         : num [1:5] 0 6.45 3.23 6.45 0\n  ..$ Neutral          : num [1:5] 25.8 22.6 16.1 32.3 19.4\n  ..$ Agree            : num [1:5] 38.7 45.2 29 38.7 35.5\n  ..$ Strongly Agree   : num [1:5] 29 19.4 48.4 22.6 38.7\n $ items   :'data.frame':   31 obs. of  5 variables:\n  ..$ Beyond the content  : Factor w/ 5 levels \"Strongly Disagree\",..: 3 5 5 3 4 4 3 1 4 5 ...\n  ..$ Analyze errors      : Factor w/ 5 levels \"Strongly Disagree\",..: 4 1 5 4 4 3 2 5 5 4 ...\n  ..$ Provide facts       : Factor w/ 5 levels \"Strongly Disagree\",..: 3 5 4 5 5 5 4 4 4 5 ...\n  ..$ Develop writing     : Factor w/ 5 levels \"Strongly Disagree\",..: 4 3 5 4 2 3 4 3 5 5 ...\n  ..$ Independent learning: Factor w/ 5 levels \"Strongly Disagree\",..: 4 5 4 5 4 4 4 3 4 3 ...\n $ grouping: NULL\n $ factors : NULL\n $ nlevels : int 5\n $ levels  : chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ...\n - attr(*, \"class\")= chr \"likert\"\n\n\nR code\n# create the chart\nlikert_100_pct_bar(likert_list)\n\n\n\n\n\nFigure 10: Row-record data, editing labels before invoking likert().\n\n\n\n\n\n\nData table\nThe results component can also be used to construct a summary data table.\n\n\nR code\nlikert_list$results\n\n\n                  Item Strongly Disagree Disagree  Neutral    Agree\n1   Beyond the content          6.451613 0.000000 25.80645 38.70968\n2       Analyze errors          6.451613 6.451613 22.58065 45.16129\n3        Provide facts          3.225806 3.225806 16.12903 29.03226\n4      Develop writing          0.000000 6.451613 32.25806 38.70968\n5 Independent learning          6.451613 0.000000 19.35484 35.48387\n  Strongly Agree\n1       29.03226\n2       19.35484\n3       48.38710\n4       22.58065\n5       38.70968\n\n\nRounding the digits, we produce a publication-ready table. I’m assuming the abbreviated question labels are OK—if not, each could be replaced with its complete assertion. In this form, the rows of the table are in the same order as the rows of the chart—a structure that could be useful to the reader.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem\nStrongly Disagree\nDisagree\nNeutral\nAgree\nStrongly Agree\n\n\n\n\nBeyond the content\n6.5\n0.0\n25.8\n38.7\n29.0\n\n\nAnalyze errors\n6.5\n6.5\n22.6\n45.2\n19.4\n\n\nProvide facts\n3.2\n3.2\n16.1\n29.0\n48.4\n\n\nDevelop writing\n0.0\n6.5\n32.3\n38.7\n22.6\n\n\nIndependent learning\n6.5\n0.0\n19.4\n35.5\n38.7\n\n\n\n\n\n\nThe values in this table were computed by likert from the fictitious row-record data. The numbers agree with the source data table."
  },
  {
    "objectID": "posts/2022-02-19-facets-not-small-multiples/index.html",
    "href": "posts/2022-02-19-facets-not-small-multiples/index.html",
    "title": "Facets that are not small multiples",
    "section": "",
    "text": "Summary\n\n\n\nFor data structures having two categorical variables and one quantitative variable, this post illustrates how category independence or dependence influences chart design. Graphs with independent categories (multiway data) are easily created in ggplot2 with the facet_wrap() function; data with dependent categories require facet_grid() with its scales and space arguments to treat unequal vertical scales.\nSmall multiple design is a good design choice for many data structures. To facilitate visual comparisons, every small-multiple frame (variously called panels, facets, or subplots) has identical scales.\nMultiway data—a data structure comprising two independent categorical variables and one quantitative response variable—is well-matched to small multiple design.\nHowever, if the categories happen to be dependent, the data are not multiway and the small multiple design fails. Having come across data of this type in a recent article, I thought it would be interesting to illustrate, given one quantitative variable and two categorical variables, how category independence or dependence influences chart design.\nI start with a multiway data set and point out that, as a small-multiple design, the panels share common scales. In ggplot2, small multiples are usually created using facet_wrap().\nThe second example has data with dependent categories. The panels share a common, horizontal, quantitative scale but have different category scales, yielding facets that are not small multiples. I use facet_grid() with its scales and space arguments to treat the unequal vertical scales.\nThe R code for the post is listed under the “R code” pointers."
  },
  {
    "objectID": "posts/2022-02-19-facets-not-small-multiples/index.html#multiway-example",
    "href": "posts/2022-02-19-facets-not-small-multiples/index.html#multiway-example",
    "title": "Facets that are not small multiples",
    "section": "Multiway example",
    "text": "Multiway example\nThe literal textbook example of multiway data and chart design is the livestock chart by Cleveland (1993, 303). The data set contains counts of 5 types of farm animals in 26 countries in 1967. The independent categories are country and animal type; the quantitative variable is the count.\nI obtained a reproduction of the data from (UCLA 2021) and saved it in the blog data directory as a CSV file.\n\n\nR code\n# read the livestock data\nDT <- fread(\"data/livestock-1967.csv\")\n\n# examine the data\nDT[]\n\n\n     livestock_type        country    count\n             <char>         <char>    <num>\n  1:         Cattle        Albania   478000\n  2:         Cattle        Austria  2536000\n  3:         Cattle        Belgium  3246000\n  4:         Cattle       Bulgaria  1796000\n  5:         Cattle Czechoslovakia  5131000\n ---                                       \n126:          Sheep    Switzerland   336000\n127:          Sheep         Turkey 70093000\n128:          Sheep United Kingdom 32888000\n129:          Sheep  Russia et al. 21000000\n130:          Sheep     Yugoslavia  7384000\n\n\nThe countries are assigned to the rows such that the median count by country increases from bottom to top. The livestock are assigned to the panels such that median count by livestock type increases in graphical order: increasing from left to right and from bottom to top. The logarithm of counts is used for the quantitative scale counts vary by more than four powers of 10.\n\n\nR code\nggplot(data = DT, mapping = aes(x = log10(count), y = reorder(country, count, median))) +\n  geom_point() + \n  facet_wrap(vars(reorder(livestock_type, count, median)), as.table = FALSE) +\n  labs(x = expression('Log'[10]~'number of livestock'), y = \"\")\n\n\n\n\n\nFigure 1: Cleveland’s livestock multiway chart illustrates small-multiple design.\n\n\n\n\nTypical of small multiple charts in general, all five panels have identical horizontal scales (the count) and identical vertical axes (countries). It follows that the size and aspect ratio of each panel are also identical."
  },
  {
    "objectID": "posts/2022-02-19-facets-not-small-multiples/index.html#when-categories-are-dependent",
    "href": "posts/2022-02-19-facets-not-small-multiples/index.html#when-categories-are-dependent",
    "title": "Facets that are not small multiples",
    "section": "When categories are dependent",
    "text": "When categories are dependent\nThe data set that inspired this post is from an article on a creative expression assignment used in a first-year engineering course (Chambers and Reid 2021). In response to COVID-19, the course had transitioned from a highly interactive, in-person experience to an asynchronous, online model.\n\nThe instructors designed an assignment to encourage students to creatively express how the course interruption and transition online was affecting them. The assignment encouraged complete freedom of expression and choice of media.\n\nA data table in the article reports how the student work is coded: 28 creative genres (prose, lyrics, music performance, dance, YouTube, etc.) grouped into 6 media categories (writing, performance, video, graphics, etc.). The quantitative variable is the count of encodings by genre.\nSome submissions covered multiple media and genres, for example, an original song in a video would be coded as both. Thus the total of the count column (304 encodings) exceeds the number of submissions (N = 265). The percent column is a derived variable that reports the count as a percentage of N. The sum of the percent column is therefore greater than 100%.\nThe data are available in the blog data directory as a CSV file.\n\n\nR code\n# import the data\nDT <- fread(\"data/creative-assignment-2021.csv\")\n\n# print the data table\nDT[]\n\n\n         medium                 genre count percent\n         <char>                <char> <int>   <num>\n 1:     Writing                 Prose     6     2.3\n 2:     Writing                 Essay    32    12.1\n 3:     Writing              Word art     6     2.3\n 4:     Writing    Poetry (not haiku)    32    12.1\n 5:     Writing                 Haiku     4     1.5\n 6:       Music                Lyrics     3     1.1\n 7:       Music              Playlist     3     1.1\n 8: Performance Music from instrument     6     2.3\n 9: Performance  Performance of music     6     2.3\n10: Performance                 Dance     2     0.8\n11: Performance           Spoken word     2     0.8\n12:   Sculpture      Arranged objects     6     2.3\n13:   Sculpture             Sculpture     2     0.8\n14:   Sculpture                  Lego     2     0.8\n15:       Video                TikTok     7     2.6\n16:       Video               YouTube     4     1.5\n17:       Video            Short-form     9     3.4\n18:       Video                 Music     3     1.1\n19:       Video           Spoken word     5     1.9\n20:    Graphics               Collage    13     4.9\n21:    Graphics              Painting    18     6.8\n22:    Graphics       Drawing by hand    58    21.9\n23:    Graphics   Drawing by computer    10     3.8\n24:    Graphics           Photography    15     5.7\n25:    Graphics               Cartoon    18     6.8\n26:    Graphics                 Emoji     6     2.3\n27:    Graphics                  Meme    22     8.3\n28:    Graphics            Web design     4     1.5\n         medium                 genre count percent\n\n\nThe graph I have in mind would have media type assigned to rows and media category assigned to panels. Unlike the livestock example, however, the categorical variables in these data are not independent. For example, web design is associated only with graphics, essay is associated only with writing, etc.\nIn my first attempt, I use facet_wrap() like I did with the livestock data. The visual problem is obvious…every row has a data marker in one panel only. Because the categories are not independent, the small-multiple design fails.\n\n\nR code\n# create the first chart \np <- ggplot(data = DT, mapping = aes(x = percent, y = reorder(genre, count))) +\n  geom_point() + \n  facet_wrap(vars(reorder(medium, count)) , as.table = FALSE) +\n  labs(y = \"\")\n\n# display the result\np\n\n\n\n\n\nFigure 2: Small-multiple chart design does not work when categories are dependent.\n\n\n\n\nThe scales = \"free_y\" argument of facet_wrap() replaces the common y-scale with only those row labels associated with a panel. I also use the ncol argument to stack the panels in one column with all rows labels aligned on the left. This graph has the essential layout I had in mind—a common quantitative scale but different vertical scales, yielding facets that are not small multiples.\n\n\nR code\n# edit the previous chart \np <- p +\n   facet_wrap(vars(reorder(medium, count)) , as.table = FALSE, scales = \"free_y\", ncol = 1)\n\n# display the result\np\n\n\n\n\n\nFigure 3: The quantitative scale is shared; the categorical scales are not.\n\n\n\n\nBecause facet_wrap() creates panels of equal height, the rows in this case are unequally spaced.\nI switch to facet_grid() to space the rows equally in panels of unequal height. The space = \"free_y\" argument is added to make the panel height proportional to the length of the y scale.\n\n\nR code\n# edit the previous chart \np <- p  +\n  facet_grid(rows = vars(reorder(medium, count)), \n             as.table = FALSE, \n             scales = \"free_y\",\n             space = \"free_y\")\n\n# display the result\np\n\n\n\n\n\nFigure 4: Applying consistent row spacing, facet height depends on the number of categorical levels."
  },
  {
    "objectID": "posts/2022-02-19-facets-not-small-multiples/index.html#editing-the-chart",
    "href": "posts/2022-02-19-facets-not-small-multiples/index.html#editing-the-chart",
    "title": "Facets that are not small multiples",
    "section": "Editing the chart",
    "text": "Editing the chart\nWhile the overall layout above is what I want, I would prefer to move the panel labels from the right-hand side to the top of each panel. I could not find a way to do that, so I removed the right-hand label and wrote the media label inside the panel. I edited some other aesthetics as well.\n\n\nR code\n# create a y-coordinate for a text geom\nDT <- DT[, y_coord_media := .N/2 + 0.5, by = medium]\n\n# create secondary axis data, omit some labels to avoid overprinting\ncount_scale <- sort(unique(DT$count))\ntop_axis <- data.table(count_scale)\ntop_axis[, count_label := as.character(count_scale)]\nomit_labels <- c(\"3\", \"5\", \"7\", \"9\", \"15\")\ntop_axis[count_label %chin% omit_labels, count_label := \"\"]\n\n# ratio for secondary axis transformation\nscale_trans <- sum(DT$count) / sum(DT$percent)\n\n# graph\nggplot(data = DT, mapping = aes(x = percent, y = reorder(genre, count))) +\n  geom_point(size = 2) +\n  facet_grid(rows = vars(reorder(medium, count)), \n             as.table = FALSE, \n             scales = \"free_y\",\n             space = \"free_y\") +\n  labs(x = \"Genre encodings (%)\", y = \"Genre\") +\n  theme_light() +\n  theme(strip.text.y = element_blank(), \n        panel.grid.minor = element_blank(),\n        axis.title.y = element_text(angle = 0, hjust = 1, vjust = 0.5)) +\n  geom_text(aes(x = 24, y = y_coord_media, label = medium, hjust = 1), color = \"gray50\") +\n  scale_x_continuous(sec.axis = sec_axis(trans = function(z) (z * scale_trans), \n                                         name = \"Count of genre encodings\", \n                                         breaks = top_axis$count_scale, \n                                         labels = top_axis$count_label))\n\n\n\n\n\nFigure 5: The final design incorporates a second horizontal scale along the top of the figure with counts corresponding to specific data markers.\n\n\n\n\nFeatures of the graph\n\nfacet_grid() as shown earlier for panels of unequal height with rows equally spaced.\ngeom_text() for panel labels, vertically centered.\nsec_axis() for a secondary scale along the top of the chart showing counts of genre encodings from the data table.\ntheme_light() for gray lines on white background to focus attention on the data.\nAll text is oriented horizontally for ease of reading.\nMedia are ordered by increasing counts (total count rather than median) from bottom to top.\nWithin a panel, genres are similarly ordered."
  },
  {
    "objectID": "posts/2022-02-19-facets-not-small-multiples/index.html#final-thoughts",
    "href": "posts/2022-02-19-facets-not-small-multiples/index.html#final-thoughts",
    "title": "Facets that are not small multiples",
    "section": "Final thoughts",
    "text": "Final thoughts\nRegarding their data table, the authors write,\n\n… some media were selected by large numbers of students, such as drawings by hand or computer, and writing such as poems and essays.\n\nThe graph supports this assertion but emphasizes visually a couple of other points as well. Drawings by hand, essays, and non-haiku poetry were by far the most popular genres (adding up to nearly 50% of the submission encodings) and graphics was by far the most popular medium (about 60% of the encodings).\nMainly this chart gave me a chance to clarify something that my students would sometimes overlook—that a data structure with two categories and one quantitative variable are multiway data if and only if the categories are independent and a value of the response exists for each combination of levels of the two categories. Otherwise, we cannot expect to use a small-multiple design."
  }
]